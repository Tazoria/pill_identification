{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 필요한 모듈들 임포트"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine tuning\n",
    "사전 훈련된 모델을 기반으로 아키텍쳐를 새로운 목적에 맞게 변형하고 이미 학습된 모델의 가중치를 미세하게 조정해 학습시키는 방법\n",
    "    - 사전 훈련된 모델의 가중치를 초기값으로 사용하고 추가로 학습\n",
    "    - CNN 베이스의 사전학습 모델을 사용할 때에는 이전에 학습한 내용들을 모두 잊어버릴 위험이 있기 때문에 작은 learning rate를 사용하는것이 바람직함\n",
    "[방법1] 모델 전체를 새로 학습\n",
    "- 사전 학습 모델의 구조만 사용하면서, 자신의 데이터셋에 맞게 모델을 전부 새롭게 학습시키는 방법\n",
    "- 데이터의 크기가 크고 유사성이 작을 때 사용\n",
    "[방법2] Conv base는 일부분 고정(Freezing)하고 나머지 Conv Base 계층과 Classifier를 새롭게 학습\n",
    "- Conv base: 합성곱 층과 풀링 층이 여러 겹 쌓여있는 부분으로 특징을 추출하는 역할\n",
    "- Classifier: 주로 완전연결계층으로 구성되며 Conv base가 추출한 특징들을 잘 학습해 각각의 샘플들을 알맞은 class로 분류\n",
    "- 낮은 레벨의 계층은 일반적이고 독리적인 특징(신형성)을 추출하고, 높은 레벨의 계층은 구체적이고 명확한 특징(형상)을 추출\n",
    "- 크기가  크고 유사성도 높은 데이터셋일 때\n",
    "[방법3] Conv Base는 고정하고 Classifier만 새로 학습\n",
    "- 컴퓨팅 연산 능력이 부족하거나, 데이터셋이 너무 작을 때, 혹은 적용하려는 task와 사전학습에 쓰인 데이터가 매우 비슷할 때 사용\n",
    "\n",
    "[크기가 작고 유사성도 작은 데이터]\n",
    "- 방법2를 쓰되 조금 더 깊은 계층까지 새로 학습시키\n",
    "- Data Augmentation 하기\n",
    "\n",
    "[Feature Extraction]\n",
    "사전 훈련된 모델의 하위 층을 동결하고, 상위 층을 새로운 작업을 위해 수정하지 않고 사용하는 것 -> 데이터분류기(마지막 완전연결층) 부분만 새로 만드는 것\n",
    "    - 사전 훈련된 모델(고정): 중요한 특성 추출(학습 X)\n",
    "    - 데이터분류기: 추출된 특성을 입력받아 최종적으로 이미지에 대한 클래스를 분류(학습O)\n",
    "    - 가능한 모델: Xception, Inception V3, ResNet50, VGG16, VGG19, MobileNet\n",
    "\n",
    "[ 분류기 수정하는 방법 ]\n",
    "Fine tunning을 하기 전 input값으로 받는 이미지의 크기는 무조건 확인해야함\n",
    "    - 대부분의 모델은 (224, 224)이지만 inception_v3의 경우 (299, 299)\n",
    "1. print(model)로 마지막 층의 in_features 확인\n",
    "2. nn.Linear(in_features, num_classes)로 클래스 수 변경\n",
    "    - 예시1: Resnet\n",
    "        - (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
    "            - => model.fc = nn.Linear(512, num_classes)\n",
    "    - 예시2: Alexnet\n",
    "        - (classifier): Sequential(... (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "            - => model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "    - 예시3(특이구조): Squeezenet\n",
    "        - - output은 classifier의 첫번째 레이어인 1X1 convolution layer로부터 나옴\n",
    "        - (classifier): Sequential((0): Dropout(p=0.5)  (1): Conv2d(512, 1000, kernel_size=13, stride=1, padding=0)  (2): ReLU(inplace)  (3): AvgPool2d(kernel_size=13, stride=1, padding=0))\n",
    "            -  => model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "    - 예시4(특이구조): Inception v3\n",
    "        - Rethinking을 하기 때문에 학습과정에서 output이 두개의 레이어로부터 나옴\n",
    "        - 두번째 output(auxiliary output): AuxLogits 부분을 포함하는 네트워크에 포함됨\n",
    "        - 주된 output은 네트워크의 마지막 레이어에서 출력됨\n",
    "            -  test 시에는 이 output만 고려함\n",
    "        - (AuxLogits): InceptionAux(... (fc): Linear(in_feature=768, out_features=1000, bias=True) ... (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
    "            -  finetune 하기 위해서는 두 레이어를 reshape 해줘야함\n",
    "            -  => model.AuxLogits.fc = nn.Linear(768, num_classes)\n",
    "            -  model.fc = nn.Linear(2048, nuum_classes)\n",
    "\n",
    "[ 사용가능한 함수들 ]\n",
    "- get_model(name, **config): 모델 이름과 환경설정을 인수로 받아 해당 모델의 인스턴스를 반환\n",
    "    - get_model(\"quantized_mobilenet_v3_large\", weights=\"DEFAULT\")\n",
    "- get_model_weight(name): 해당 모델의 열거형 가중치 클래스 반환\n",
    "    - 예1: get_model_weights(\"quantized_mobilenet_v3_large\")\n",
    "    - 예2: get_model_weights(torchvision.models.quantization.mobilenet_v3_large)\n",
    "    - 예1 = 예2\n",
    "- get_weight(name): 열거형 가중치 변수의 이름으로 값을 가져옴\n",
    "    - 예: get_weight(\"MobileNet_V3_Large_QuantizedWeights.DEFAULT\")\n",
    "- list_models(\\[module]): 해당 이름으로 등록된 모델 목록을 반환\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import time\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T02:07:08.026575600Z",
     "start_time": "2023-10-02T02:07:07.991670500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 사용가능한 모델 확인\n",
    "# for name in dir(torchvision.models):\n",
    "#     print(name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 구성"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "\"\"\"\n",
    "        MobileNet V3 main class\n",
    "\n",
    "        Args:\n",
    "            inverted_residual_setting (List[InvertedResidualConfig]): Network structure\n",
    "            last_channel (int): The number of channels on the penultimate layer\n",
    "            num_classes (int): Number of classes\n",
    "            block (Optional[Callable[..., nn.Module]]): Module specifying inverted residual building block for mobilenet\n",
    "            norm_layer (Optional[Callable[..., nn.Module]]): Module specifying the normalization layer to use\n",
    "            dropout (float): The droupout probability\n",
    "        \"\"\"\n",
    "# MobileNetV3 Large 모델 구현\n",
    "class CustomMobileNetV3Large(nn.Module):\n",
    "    def __init__(self, num_classes=100):\n",
    "        super(CustomMobileNetV3Large, self).__init__()\n",
    "        self.features = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.DEFAULT, progress=True).features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(960, num_classes, 1, 1, 0),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T02:07:18.917693600Z",
     "start_time": "2023-10-02T02:07:18.892760400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 테스트 데이터셋\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm_notebook(valid_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 추론 - 임의의 이미지"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img = cv2.imread('apple.jpg')\n",
    "img = transform_test(img).unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(img.to(device))\n",
    "\n",
    "_, predicted_class = torch.max(outputs, 1)\n",
    "predicted_class = predicted_class.item()\n",
    "predicted_class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 작업중"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "model_list = ['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet', 'inception', 'mobilenet']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# 모델학습 헬퍼 함수\n",
    "def train_models(model, dataloaders, criterion, optimizer, num_epochs=10, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch} / {num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # 각 에폭은 학습/검증 phase를 가짐\n",
    "        for phase in ['train', 'val']:\n",
    "            print(f'>>>>> phase: {phase}<<<<<')\n",
    "            if phase == 'train':\n",
    "                model.train()  # 트레이닝 모드 설정\n",
    "            else:\n",
    "                model.eval()  # 추론 모드 설정\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # 데이터 학습하기\n",
    "            for inputs, labels in tqdm_notebook(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # 파라미터 기울기 초기화\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # 학습 모드인 경우에만 history 추적\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # 모델의 ouptut과 loss를 구함\n",
    "                    # inception의 경우 학습시 auxiliary output이 있는 특수 케이스임.\n",
    "                    #   학습시: final output과 auxiliary output을 더하는 과정이 필요함\n",
    "                    #   테스트시: final output만 고려\n",
    "                    # Auxilary output을 같이 고려해야하는 학습단계\n",
    "                    if is_inception and phase == 'train':\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4 * loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # 학습(backward + optimize)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # loss 구하기\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # 모델 깊은복사\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.4f}'.format(best_acc))\n",
    "\n",
    "    # 베스트 모델 가중치를 로드\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T02:16:23.638121200Z",
     "start_time": "2023-10-02T02:16:23.613165300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 모델 파라미터의 requires_grad 속성\n",
    "- 기본적으로 사전  훈련된 모델을 로드할 때 모든 매개변수의 requires_grad = True로 설정되어 있음\n",
    "    - True: 처음부터 훈련하거나 fine tuning할 때는 True\n",
    "    - False(Freeze): 기존 layer의 weight를 고정"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T02:16:24.933915200Z",
     "start_time": "2023-10-02T02:16:24.913967200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 초기화"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True, quantize=False):\n",
    "    # 모델마다 다르게 지정될 변수들 초기화\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == 'resnet':\n",
    "        if quantize:\n",
    "            '''Quantized Resnet50'''\n",
    "            weights = models.quantization.ResNet50_QuantizedWeights.DEFAULT\n",
    "            model_ft = models.quantization.resnet50(weights=weights, quantize=True)\n",
    "        else:\n",
    "            '''Resnet50'''\n",
    "            model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'mobilenet':\n",
    "        if quantize:\n",
    "            '''Quantized Mobilenet v3 large'''\n",
    "            weights = models.quantization.MobileNet_V3_Large_QuantizedWeights.DEFAULT\n",
    "            model_ft = models.quantization.mobilenet_v3_large(weigts=weights, quantize=True)\n",
    "            num_ftrs = model_ft.classifier[3].in_features\n",
    "            model_ft.classifier[3] = nn.Linear(num_ftrs, num_classes)\n",
    "        else:\n",
    "            model_ft = CustomMobileNetV3Large(num_classes=500).to(device)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'alexnet':\n",
    "        '''AlexNet'''\n",
    "        model_ft = models.alexnet(pretrianed=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_featrues\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'vgg':\n",
    "        '''VGG11_bn'''\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'squeezenet':\n",
    "        '''Squeezenet 1.0'''\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'densenet':\n",
    "        '''Densenet 121'''\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'inception':\n",
    "        '''Inception V3'''\n",
    "        if quantize:\n",
    "            weights = models.quantization.Inception_V3_QuantizedWeights.DEFAULT\n",
    "            model_ft = models.quantization.inception_v3(weights=weights, quantize=True)\n",
    "        else:\n",
    "            model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 299  # 다른 모델과 다르게 299 사이즈를 사용\n",
    "    else:\n",
    "        print('모델의 이름을 잘못 입력하여 종료합니다...')\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T02:16:26.794452400Z",
     "start_time": "2023-10-02T02:16:26.772482700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train >  1001 \n",
      "val >  126 \n",
      "test >  126\n"
     ]
    }
   ],
   "source": [
    "# 데이터 경로\n",
    "data_root = f'D:/data/training/sources/cropped'\n",
    "\n",
    "# 데이터 변환\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# ImageFolder로 전체 데이터셋 생성\n",
    "dataset = datasets.ImageFolder(root=data_root, transform=data_transforms)\n",
    "batch_size = 128\n",
    "# 데이터셋 분할 (예: 80% 훈련, 20% 유효성 검사)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
    "valid_dataset, test_dataset = random_split(valid_dataset, [0.5, 0.5])\n",
    "\n",
    "# 데이터 로더 생성\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dataloaders_dict = {'train': train_dataloader, 'val': valid_dataloader, 'test': test_dataloader}\n",
    "\n",
    "print('train > ', len(train_dataloader), '\\nval > ', len(valid_dataloader), '\\ntest > ', len(test_dataloader))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T02:16:29.627060700Z",
     "start_time": "2023-10-02T02:16:28.369891700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 0\n",
      "----------\n",
      ">>>>> phase: train<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1001 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78be01c119b24ecf9054e2c5af2db621"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'mobilenet'\n",
    "num_classes = 500\n",
    "feature_extract = False\n",
    "use_pretrained = False\n",
    "quantize = False\n",
    "\n",
    "\n",
    "\n",
    "model_pretrained, input_size_pretrained = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True, quantize=quantize)\n",
    "model_pretrained = model_pretrained.to(device)\n",
    "\n",
    "optimizer = optim.NAdam(model_pretrained.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print('device > ', device)\n",
    "model_pretrained, hist_pretrained = train_models(model_pretrained, dataloaders_dict, criterion, optimizer, num_epochs=1, is_inception=False)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-02T02:16:54.415007300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_scratch, input_size_scratch = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained, quantize=quantize)\n",
    "model_scratch = model_scratch.to(device)\n",
    "\n",
    "model_scratch, hist_scratch = train_models(model_scratch, dataloaders_dict, criterion, optimizer, num_epochs=1, is_inception=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "ohist = []\n",
    "shist = []\n",
    "\n",
    "ohist = [h.cpu().numpy() for h in hist_pretrained]\n",
    "shist = [h.cpu().numpy() for h in hist_scratch]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_pretrained2, hist_pretrained2 = train_models(model_pretrained, dataloaders_dict, criterion, optimizer, num_epochs=1, is_inception=False)\n",
    "model_scratch2, hist_scratch2 = train_models(model_scratch, dataloaders_dict, criterion, optimizer, num_epochs=1, is_inception=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 모델 인스턴스 생성하고 구조 확인하기\n",
    "# # 1. 일반 레즈넷, 마지막 fc레이어만 변경\n",
    "# model_name = 'resnet'\n",
    "# num_classes = 500\n",
    "# feature_extract = False\n",
    "# use_pretrained = True\n",
    "# quantize = False\n",
    "#\n",
    "# model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True, quantize=False)\n",
    "# print(model_name)\n",
    "# print(model_ft)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 2. 양자화된 레즈넷, 마지막 fc레이어만 변경 - QuantizedLinear 나와야하는데 일반 Linear만나옴\n",
    "# model_name = 'resnet'\n",
    "# num_classes = 100\n",
    "# feature_extract = False\n",
    "# use_pretrained = True\n",
    "# quantize = True\n",
    "#\n",
    "# model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True, quantize=True)\n",
    "# print('quantized ' + model_name)\n",
    "# print(model_ft)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 헬퍼함수 없이 만든 양자화된 레즈넷\n",
    "# weights = models.quantization.ResNet50_QuantizedWeights.DEFAULT\n",
    "# model_ft = models.quantization.resnet50(weights=weights, quantize=True)\n",
    "# print(model_ft)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# weights = models.quantization.MobileNet_V3_Large_QuantizedWeights.DEFAULT\n",
    "# model_ft = models.quantization.mobilenet_v3_large(weigts=weights, quantize=True)\n",
    "# print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
