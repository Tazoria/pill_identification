{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 필요한 모듈들 임포트"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine tuning\n",
    "사전 훈련된 모델을 기반으로 아키텍쳐를 새로운 목적에 맞게 변형하고 이미 학습된 모델의 가중치를 미세하게 조정해 학습시키는 방법\n",
    "    - 사전 훈련된 모델의 가중치를 초기값으로 사용하고 추가로 학습\n",
    "    - CNN 베이스의 사전학습 모델을 사용할 때에는 이전에 학습한 내용들을 모두 잊어버릴 위험이 있기 때문에 작은 learning rate를 사용하는것이 바람직함\n",
    "[방법1] 모델 전체를 새로 학습\n",
    "- 사전 학습 모델의 구조만 사용하면서, 자신의 데이터셋에 맞게 모델을 전부 새롭게 학습시키는 방법\n",
    "- 데이터의 크기가 크고 유사성이 작을 때 사용\n",
    "[방법2] Conv base는 일부분 고정(Freezing)하고 나머지 Conv Base 계층과 Classifier를 새롭게 학습\n",
    "- Conv base: 합성곱 층과 풀링 층이 여러 겹 쌓여있는 부분으로 특징을 추출하는 역할\n",
    "- Classifier: 주로 완전연결계층으로 구성되며 Conv base가 추출한 특징들을 잘 학습해 각각의 샘플들을 알맞은 class로 분류\n",
    "- 낮은 레벨의 계층은 일반적이고 독리적인 특징(신형성)을 추출하고, 높은 레벨의 계층은 구체적이고 명확한 특징(형상)을 추출\n",
    "- 크기가  크고 유사성도 높은 데이터셋일 때\n",
    "[방법3] Conv Base는 고정하고 Classifier만 새로 학습\n",
    "- 컴퓨팅 연산 능력이 부족하거나, 데이터셋이 너무 작을 때, 혹은 적용하려는 task와 사전학습에 쓰인 데이터가 매우 비슷할 때 사용\n",
    "\n",
    "[크기가 작고 유사성도 작은 데이터]\n",
    "- 방법2를 쓰되 조금 더 깊은 계층까지 새로 학습시키\n",
    "- Data Augmentation 하기\n",
    "\n",
    "[Feature Extraction]\n",
    "사전 훈련된 모델의 하위 층을 동결하고, 상위 층을 새로운 작업을 위해 수정하지 않고 사용하는 것 -> 데이터분류기(마지막 완전연결층) 부분만 새로 만드는 것\n",
    "    - 사전 훈련된 모델(고정): 중요한 특성 추출(학습 X)\n",
    "    - 데이터분류기: 추출된 특성을 입력받아 최종적으로 이미지에 대한 클래스를 분류(학습O)\n",
    "    - 가능한 모델: Xception, Inception V3, ResNet50, VGG16, VGG19, MobileNet\n",
    "\n",
    "[ 분류기 수정하는 방법 ]\n",
    "Fine tunning을 하기 전 input값으로 받는 이미지의 크기는 무조건 확인해야함\n",
    "    - 대부분의 모델은 (224, 224)이지만 inception_v3의 경우 (299, 299)\n",
    "1. print(model)로 마지막 층의 in_features 확인\n",
    "2. nn.Linear(in_features, num_classes)로 클래스 수 변경\n",
    "    - 예시1: Resnet\n",
    "        - (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
    "            - => model.fc = nn.Linear(512, num_classes)\n",
    "    - 예시2: Alexnet\n",
    "        - (classifier): Sequential(... (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "            - => model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "    - 예시3(특이구조): Squeezenet\n",
    "        - - output은 classifier의 첫번째 레이어인 1X1 convolution layer로부터 나옴\n",
    "        - (classifier): Sequential((0): Dropout(p=0.5)  (1): Conv2d(512, 1000, kernel_size=13, stride=1, padding=0)  (2): ReLU(inplace)  (3): AvgPool2d(kernel_size=13, stride=1, padding=0))\n",
    "            -  => model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "    - 예시4(특이구조): Inception v3\n",
    "        - Rethinking을 하기 때문에 학습과정에서 output이 두개의 레이어로부터 나옴\n",
    "        - 두번째 output(auxiliary output): AuxLogits 부분을 포함하는 네트워크에 포함됨\n",
    "        - 주된 output은 네트워크의 마지막 레이어에서 출력됨\n",
    "            -  test 시에는 이 output만 고려함\n",
    "        - (AuxLogits): InceptionAux(... (fc): Linear(in_feature=768, out_features=1000, bias=True) ... (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
    "            -  finetune 하기 위해서는 두 레이어를 reshape 해줘야함\n",
    "            -  => model.AuxLogits.fc = nn.Linear(768, num_classes)\n",
    "            -  model.fc = nn.Linear(2048, nuum_classes)\n",
    "\n",
    "[ 사용가능한 함수들 ]\n",
    "- get_model(name, **config): 모델 이름과 환경설정을 인수로 받아 해당 모델의 인스턴스를 반환\n",
    "    - get_model(\"quantized_mobilenet_v3_large\", weights=\"DEFAULT\")\n",
    "- get_model_weight(name): 해당 모델의 열거형 가중치 클래스 반환\n",
    "    - 예1: get_model_weights(\"quantized_mobilenet_v3_large\")\n",
    "    - 예2: get_model_weights(torchvision.models.quantization.mobilenet_v3_large)\n",
    "    - 예1 = 예2\n",
    "- get_weight(name): 열거형 가중치 변수의 이름으로 값을 가져옴\n",
    "    - 예: get_weight(\"MobileNet_V3_Large_QuantizedWeights.DEFAULT\")\n",
    "- list_models(\\[module]): 해당 이름으로 등록된 모델 목록을 반환\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "import pandas\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from thop import profile\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "from torch.utils.data import random_split, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from custom_models import CustomMobileNetV3Large, QuantizedCustomMobileNetV3Large, CustomMnasNet1_3, QuantizedCustomMnasNet1_3\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T15:51:03.941843Z",
     "start_time": "2023-10-10T15:50:56.491951400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "model_list = ['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet', 'inception', 'mobilenet']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 모델 파라미터의 requires_grad 속성\n",
    "- 기본적으로 사전  훈련된 모델을 로드할 때 모든 매개변수의 requires_grad = True로 설정되어 있음\n",
    "    - True: 처음부터 훈련하거나 fine tuning할 때는 True\n",
    "    - False(Freeze): 기존 layer의 weight를 고정"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 모델학습 헬퍼 함수\n",
    "def train_models(model, dataloaders, criterion, optimizer, num_epochs=5, is_inception=False, quantize=False):\n",
    "    torch.cuda.empty_cache()\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    val_top5_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    patience = 3\n",
    "    no_improvement_count = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1} / {num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # 각 에폭은 학습/검증 phase를 가짐\n",
    "        for phase in ['train', 'val']:\n",
    "            print(f'>>>>> phase: {phase}<<<<<')\n",
    "            if phase == 'train':\n",
    "                model.train()  # 트레이닝 모드 설정\n",
    "            else:\n",
    "                if quantize == True:\n",
    "                    # 모델을 양자화 + 추론모드\n",
    "                    model = torch.quantization.convert(model.eval(), inplace=False)\n",
    "                else:\n",
    "                    model.eval()  # 추론 모드 설정\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_top5_corrects = 0\n",
    "\n",
    "            # 데이터 학습하기\n",
    "            for inputs, labels in tqdm_notebook(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # 파라미터 기울기 초기화\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # 학습 모드인 경우에만 history 추적\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # 모델의 ouptut과 loss를 구함\n",
    "                    # inception의 경우 학습시 auxiliary output이 있는 특수 케이스임.\n",
    "                    #   학습시: final output과 auxiliary output을 더하는 과정이 필요함\n",
    "                    #   테스트시: final output만 고려\n",
    "                    # Auxilary output을 같이 고려해야하는 학습단계\n",
    "                    if is_inception and phase == 'train':\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4 * loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # top-5 정확도 계산\n",
    "                    _,top5_preds = torch.topk(outputs, 5)\n",
    "                    top5_corrects = torch.sum(top5_preds == labels.view(-1, 1))\n",
    "\n",
    "                    # 학습(backward + optimize)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        if (epoch + 1) % 5 == 0:\n",
    "                            # 모델 및 다른 정보 저장\n",
    "                            save_path = f'save/{type(model).__name__}_epoch{epoch+1}_batchsize{batch_size}_quntize({quantize}).pth'\n",
    "                            torch.save({\n",
    "                                'model_state_dict': model.state_dict(),  # 모델 가중치 저장\n",
    "                                'optimizer_state_dict': optimizer.state_dict(),  # 옵티마이저 상태 저장 (선택적)\n",
    "                                'epoch': epoch+1,  # 현재 학습 에폭 저장 (선택적)\n",
    "                                # 다른 필요한 정보 저장 (선택적)\n",
    "                            }, save_path)\n",
    "\n",
    "                # loss 구하기\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                running_top5_corrects += top5_corrects\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            epoch_top5_acc = running_top5_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # 모델 깊은복사\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                no_improvement_count = 0  # 개선이 있었으므로 카운트 초기화\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc.item())\n",
    "                val_top5_acc_history.append(epoch_top5_acc.item())\n",
    "                no_improvement_count += 1  # 개선이 없었으므로 카운트\n",
    "\n",
    "            # Early Stopping 확인\n",
    "            # if no_improvement_count >= patience:\n",
    "            #     print(f\"No improvement in validation accuracy for {patience} epochs. Early stopping...\")\n",
    "            #     break  # 학습 종료\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.4f}'.format(best_acc))\n",
    "    print('Best top5 val Acc: {:.4f}'.format(epoch_top5_acc))\n",
    "\n",
    "    # 베스트 모델 가중치를 로드\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, val_top5_acc_history\n",
    "\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T15:51:04.016150100Z",
     "start_time": "2023-10-10T15:51:03.943839700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=True, quantize=False):\n",
    "    # 모델마다 다르게 지정될 변수들 초기화\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == 'resnet':\n",
    "        if quantize:\n",
    "            '''Quantized Resnet50'''\n",
    "            weights = models.quantization.ResNet50_QuantizedWeights.DEFAULT\n",
    "            model_ft = models.quantization.resnet50(weights=weights, quantize=True)\n",
    "        else:\n",
    "            '''Resnet50'''\n",
    "            model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'mobilenet':\n",
    "        if quantize:\n",
    "            '''Quantized Mobilenet v3 large'''\n",
    "            model_ft = QuantizedCustomMobileNetV3Large(num_classes=500).to('cpu')\n",
    "\n",
    "            # 양자화 설정 - gbgemm 백엔드 사용\n",
    "            backend = 'fbgemm'\n",
    "            # 양자화 스키마 설정 (예: symmetric)\n",
    "            quantization_params = torch.quantization.get_default_qconfig(backend)\n",
    "            quantization_params = torch.quantization.QConfig(activation=quantization_params.activation, weight=quantization_params.weight)\n",
    "\n",
    "            # 양자화 준비\n",
    "            model_ft.qconfig = quantization_params\n",
    "            model_ft= torch.quantization.prepare_qat(model_ft, inplace=False)\n",
    "\n",
    "        else:\n",
    "            model_ft = CustomMobileNetV3Large(num_classes=500).to(device)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'mnasnet':\n",
    "        if quantize:\n",
    "            '''Quantized Mnasnet 1_3'''\n",
    "            model_ft = QuantizedCustomMnasNet1_3(num_classes=500).to(device)\n",
    "\n",
    "            # 양자화 설정 - gbgemm 백엔드 사용\n",
    "            backend = 'fbgemm'\n",
    "            model_ft.qconfig = torch.quantization.get_default_qat_qconfig(backend)\n",
    "\n",
    "            # 양자화 준비\n",
    "            model_ft= torch.quantization.prepare_qat(model_ft, inplace=False)\n",
    "\n",
    "        else:\n",
    "            model_ft = models.mnasnet1_3(weights=models.MNASNet1_3_Weights.IMAGENET1K_V1)\n",
    "            num_ftrs = model_ft.classifier[1].in_features\n",
    "            model_ft.classifier[1] = nn.Linear(in_features=1280, out_features=num_classes, bias=True)\n",
    "            # model_ft = CustomMnasNet1_3(num_classes=500).to(device)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'efficientnet':\n",
    "        if quantize:\n",
    "            pass\n",
    "        else:\n",
    "            model_ft = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "            num_ftrs = model_ft.classifier[1].in_features\n",
    "            model_ft.classifier[1] = nn.Linear(num_ftrs, num_classes, bias=True)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'shufflenet':\n",
    "        if quantize:\n",
    "            pass\n",
    "        else:\n",
    "            model_ft = models.shufflenet_v2_x2_0(weights=models.ShuffleNet_V2_X2_0_Weights.IMAGENET1K_V1)\n",
    "            num_ftrs = model_ft.fc.in_features\n",
    "            model_ft.fc = nn.Linear(num_ftrs, num_classes, bias=True)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'alexnet':\n",
    "        '''AlexNet'''\n",
    "        model_ft = models.alexnet(pretrianed=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_featrues\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'vgg':\n",
    "        '''VGG11_bn'''\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'squeezenet':\n",
    "        '''Squeezenet 1.0'''\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'densenet':\n",
    "        '''Densenet 121'''\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'inception':\n",
    "        '''Inception V3'''\n",
    "        if quantize:\n",
    "            weights = models.quantization.Inception_V3_QuantizedWeights.DEFAULT\n",
    "            model_ft = models.quantization.inception_v3(weights=weights, quantize=True)\n",
    "        else:\n",
    "            model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 299  # 다른 모델과 다르게 299 사이즈를 사용\n",
    "    else:\n",
    "        print('모델의 이름을 잘못 입력하여 종료합니다...')\n",
    "        exit()\n",
    "\n",
    "    return model_ft.to(device), input_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T15:51:04.031686800Z",
     "start_time": "2023-10-10T15:51:03.973756800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 데이터셋 생성1 - 증강없음"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 데이터 경로\n",
    "data_root = f'D:/data/training/sources/cropped'\n",
    "\n",
    "# 데이터 변환\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ImageFolder로 전체 데이터셋 생성\n",
    "dataset = datasets.ImageFolder(root=data_root, transform=data_transforms)\n",
    "\n",
    "# # 클래스 별 샘플 수 확인\n",
    "# class_counts = torch.bincount(torch.tensor(dataset.targets))\n",
    "# print('클래스별 샘플 수:', class_counts.unique())\n",
    "\n",
    "# 데이터셋 분할 (예: 80% 훈련, 20% 검증)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "# 데이터 로더 생성\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dataloaders_dict = {'train': train_dataloader, 'val': valid_dataloader}\n",
    "\n",
    "print('train > ', len(train_dataloader), 'val > ', len(valid_dataloader))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 데이터셋 셍성2 - 증강"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49e0bc6877f147de9caa73585c963ade"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "from torchvision import datasets\n",
    "\n",
    "# 원본 데이터 폴더 경로\n",
    "data_root = 'D:/data/training/sources/cropped'  # 데이터 경로를 본인의 환경에 맞게 수정\n",
    "\n",
    "# 분할된 데이터를 저장할 폴더 경로\n",
    "train_root = 'D:/data/training/sources/train'\n",
    "valid_root = 'D:/data/training/sources/valid'\n",
    "\n",
    "# 클래스 이름을 가져오기 위한 함수\n",
    "def get_class_names(data_root):\n",
    "    class_names = os.listdir(data_root)\n",
    "    return class_names\n",
    "\n",
    "# 클래스 이름 목록 가져오기\n",
    "class_names = get_class_names(data_root)\n",
    "\n",
    "# 클래스별로 train과 valid 폴더 생성\n",
    "for class_name in class_names:\n",
    "    train_class_dir = os.path.join(train_root, class_name)\n",
    "    valid_class_dir = os.path.join(valid_root, class_name)\n",
    "\n",
    "    os.makedirs(train_class_dir, exist_ok=True)\n",
    "    os.makedirs(valid_class_dir, exist_ok=True)\n",
    "\n",
    "# 데이터를 8:2 비율로 나누어 train과 valid 폴더에 복사\n",
    "for class_name in tqdm_notebook(class_names):\n",
    "    class_dir = os.path.join(data_root, class_name)\n",
    "    train_class_dir = os.path.join(train_root, class_name)\n",
    "    valid_class_dir = os.path.join(valid_root, class_name)\n",
    "\n",
    "    # 클래스 폴더 안의 모든 파일 목록 가져오기\n",
    "    files = os.listdir(class_dir)\n",
    "    num_files = len(files)\n",
    "    num_train_files = int(0.8 * num_files)\n",
    "\n",
    "    # 파일을 train과 valid 폴더에 복사\n",
    "    for i, file in enumerate(files):\n",
    "        src_path = os.path.join(class_dir, file)\n",
    "        if i < num_train_files:\n",
    "            dst_path = os.path.join(train_class_dir, file)\n",
    "        else:\n",
    "            dst_path = os.path.join(valid_class_dir, file)\n",
    "        copyfile(src_path, dst_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T16:01:09.389218600Z",
     "start_time": "2023-10-10T15:52:29.148341Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train >  999 val >  253\n",
      "Epoch 1 / 10\n",
      "----------\n",
      ">>>>> phase: train<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/999 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc6ed61a8c5f47bea6dea96b5e53f2c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.9941 Acc: 0.7582\n",
      ">>>>> phase: val<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/253 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc81951dc78a48feaf08f051671e2fa1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.5053 Acc: 0.5899\n",
      "\n",
      "Epoch 2 / 10\n",
      "----------\n",
      ">>>>> phase: train<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/999 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f05ba7055935499196ce556065196757"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2200 Acc: 0.9279\n",
      ">>>>> phase: val<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/253 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5abd517a1c041da92b0f9148a8341ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.7265 Acc: 0.5643\n",
      "\n",
      "Epoch 3 / 10\n",
      "----------\n",
      ">>>>> phase: train<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/999 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8788c8f5d47d4cbb8eb5cb4acf97c363"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1674 Acc: 0.9424\n",
      ">>>>> phase: val<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/253 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f843aec5dca4cf09ad07ecb06d9084e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.4373 Acc: 0.6278\n",
      "\n",
      "Epoch 4 / 10\n",
      "----------\n",
      ">>>>> phase: train<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/999 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4789533552b46e98838dad93887ec0c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1383 Acc: 0.9521\n",
      ">>>>> phase: val<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/253 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98f0918f605a4b48ac20166cff426134"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5136 Acc: 0.8424\n",
      "\n",
      "Epoch 5 / 10\n",
      "----------\n",
      ">>>>> phase: train<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/999 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9cad1f3ef14c474d887d379e688962c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1219 Acc: 0.9579\n",
      ">>>>> phase: val<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/253 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b1e640131ad4a57887609632b9b56ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.8802 Acc: 0.6029\n",
      "\n",
      "Epoch 6 / 10\n",
      "----------\n",
      ">>>>> phase: train<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/999 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "906f6624c86b4993afde1d99cf34ca6e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1115 Acc: 0.9613\n",
      ">>>>> phase: val<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/253 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b36805f042f4e72bafd20ff5784e29a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3564 Acc: 0.8838\n",
      "\n",
      "Epoch 7 / 10\n",
      "----------\n",
      ">>>>> phase: train<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/999 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e894fb4ec264fa89743dd07468b369d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1017 Acc: 0.9644\n",
      ">>>>> phase: val<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/253 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb39aa1a8b89476e8c7a9ebf35cd6ad0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5792 Acc: 0.8241\n",
      "\n",
      "Epoch 8 / 10\n",
      "----------\n",
      ">>>>> phase: train<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/999 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d9c9f77b2f474a31bb13f612ae155510"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0932 Acc: 0.9679\n",
      ">>>>> phase: val<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/253 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53996accb87a4f73af0f927906a6c08a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6286 Acc: 0.8108\n",
      "\n",
      "Epoch 9 / 10\n",
      "----------\n",
      ">>>>> phase: train<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/999 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de018f1406c8443585e3a8390779c0af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0895 Acc: 0.9686\n",
      ">>>>> phase: val<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/253 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "352b7394d7f14f11bdf4dd0adefa9a13"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4922 Acc: 0.8453\n",
      "\n",
      "Epoch 10 / 10\n",
      "----------\n",
      ">>>>> phase: train<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/999 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "87149c86409b42aaaaa3715d836ed700"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0822 Acc: 0.9711\n",
      ">>>>> phase: val<<<<<\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/253 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0fa062ed8874b3aaa329ea03f3e55e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3139 Acc: 0.9020\n",
      "\n",
      "Training complete in 376m 34s\n",
      "Best val Acc: 0.9020\n",
      "Best top5 val Acc: 0.9897\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 변환: 데이터가 부족해 과적합이 발생한 것으로 보이므로 학습데이터 증강\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.GaussianBlur(kernel_size=(19, 19), sigma=(1.0, 2.0)),\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor=0.1, p=0.5),\n",
    "    transforms.AutoAugment(policy=transforms.autoaugment.AutoAugmentPolicy.IMAGENET, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=(-30, 30)),  # 무작위 회전 (-30도에서 30도 사이)\n",
    "    transforms.RandomAffine(degrees=(-30, 30), translate=(0.1, 0.1), shear=0.1),\n",
    "    transforms.RandomPerspective(distortion_scale=0.5, p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ImageFolder를 사용하여 train과 valid 데이터셋 생성\n",
    "train_dataset = datasets.ImageFolder(root=train_root, transform=train_transforms)\n",
    "valid_dataset = datasets.ImageFolder(root=valid_root, transform=valid_transforms)\n",
    "\n",
    "# 데이터 로더 생성\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "dataloaders_dict = {'train': train_dataloader, 'val': valid_dataloader}\n",
    "\n",
    "print('train > ', len(train_dataloader), 'val > ', len(valid_dataloader))\n",
    "\n",
    "# 학습\n",
    "\n",
    "mobilenet, input_size = initialize_model(model_name='mobilenet', num_classes=500, use_pretrained=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.NAdam(mobilenet.parameters(), lr=0.0004)\n",
    "\n",
    "mobilenet, val_acc_history, val_top5_acc_history = train_models(mobilenet, dataloaders_dict, criterion, optimizer, num_epochs=10, is_inception=False, quantize=False)\n",
    "\n",
    "accuracy_mobilenet = {\n",
    "    'top1': val_acc_history,\n",
    "    'top5': val_top5_acc_history}\n",
    "with open('save/accuracies_mobilenet_augmentated.json', 'w') as f:\n",
    "    json.dump(accuracy_mobilenet, f)\n",
    "\n",
    "save_path = f'save/mobilenet_epoch10_batch128_pretrained_Augmentated.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': mobilenet.state_dict(),  # 모델 가중치 저장\n",
    "    'optimizer_state_dict': optimizer.state_dict(),  # 옵티마이저 상태 저장 (선택적)\n",
    "    'epoch': 10,  # 현재 학습 에폭 저장 (선택적) # 다른 필요한 정보 저장 (선택적)\n",
    "}, save_path)\n",
    "\n",
    "num_epochs = 10\n",
    "plt.title(\"Mobilenet Validation Accuracy: top1 VS top5\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),val_acc_history,label=\"top1 accuracy\", color='purple')\n",
    "plt.plot(range(1,num_epochs+1),val_top5_acc_history,label=\"top5 accuracy\", color='green')\n",
    "\n",
    "plt.ylim((0,1.))\n",
    "plt.yticks([0.8, 0.9, 1.0])\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T22:29:20.095656400Z",
     "start_time": "2023-10-10T16:12:45.039297300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 데이터셋 생성3 - 흑백 + 가중치조절"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 샘플 수: tensor([1296,  216,  216,  216,  216,  216,  216,  216,  324,  324,  216,  216,\n",
      "         216,  324,  216,  216,  216,  216,  216,  216,  216,  216,  216,  324,\n",
      "         324,  324,  216,  216,  324,  324,  324,  216,  216,  216,  324,  216,\n",
      "         324,  324,  216,  216,  216,  216,  216,  216,  324,  216,  216,  324,\n",
      "        1296,  216,  216,  324,  216,  324,  324,  216,  216,  216,  324,  216,\n",
      "         216, 1296, 1296,  216,  324,  216,  216,  216,  216,  216,  324,  216,\n",
      "         324,  216,  216,  324,  216,  216, 1296,  432,  216,  216,  324,  324,\n",
      "         216,  216,  216,  216,  216,  216,  216,  216,  216,  324,  324,  324,\n",
      "         216,  324,  216,  216,  216,  216,  216,  324, 1296,  216,  324,  216,\n",
      "         216,  216,  324,  324,  324,  216,  324,  324,  324,  324,  324,  324,\n",
      "         324,  216,  216,  216,  216,  324,  216,  216,  324,  216,  216,  324,\n",
      "         216,  216,  216,  216,  216,  216,  324,  216,  324,  216,  216,  216,\n",
      "         216,  216,  216,  216,  216,  216,  324,  216,  324,  216,  216,  324,\n",
      "         324,  324,  324,  216,  216,  216,  216,  324,  216,  324,  216,  216,\n",
      "         216,  432,  216,  216,  216,  216,  324,  216,  324,  324,  324,  216,\n",
      "        1296,  216,  324,  324, 1296, 1296,  216,  216,  216,  216,  216, 1296,\n",
      "        1296,  324,  324,  324,  216,  324,  324,  324,  216,  216, 1296,  216,\n",
      "         216,  324,  216,  216,  216,  216,  216,  216,  216,  216,  216,  324,\n",
      "         216,  216,  324,  324,  324,  216,  216, 1296,  216,  216,  216,  216,\n",
      "         216,  216,  216,  324,  216,  216,  216,  216,  216,  324,  216, 1296,\n",
      "         324,  216,  324,  216,  324,  216,  216,  216,  216,  216,  216,  324,\n",
      "         324,  324, 1296,  216,  216,  216,  216,  216,  216,  216,  216,  216,\n",
      "         216,  216,  216,  324,  324,  324,  216,  216,  216,  216,  324,  216,\n",
      "         216,  216,  324,  216,  216,  216,  216,  216, 1296,  216,  216,  216,\n",
      "         216,  324,  216,  324,  216,  324,  216,  216,  216, 1296,  216,  216,\n",
      "         216,  216,  216,  324,  216,  324,  324,  216,  216,  216,  324,  324,\n",
      "         216,  324,  216,  324,  216,  216,  324,  216,  216,  324,  324,  324,\n",
      "         324,  216,  216,  216,  216,  324,  216,  324,  324,  324,  216,  216,\n",
      "         324,  216,  216,  324,  216,  216,  324,  324,  216,  324,  216,  324,\n",
      "         324,  216,  216,  324,  216,  324,  216,  324,  324,  216,  216,  324,\n",
      "         216,  216,  324,  216,  216,  324,  324,  216,  216,  324,  324,  216,\n",
      "         216,  216,  216,  324,  324,  324,  216,  324,  324, 1296,  216,  216,\n",
      "         216,  324,  216,  324,  216,  324,  324,  324,  216, 1296,  324,  324,\n",
      "         216,  216,  324,  216,  324,  324,  216,  324, 1296,  216,  216, 1296,\n",
      "        1296,  216,  324,  216,  216,  324,  216,  216,  216,  216,  324,  216,\n",
      "        1296,  216,  216,  216, 1296, 1296, 1296, 1296,  216,  216,  324,  216,\n",
      "         324,  324,  216,  216,  324,  324,  324,  324,  216,  216,  216,  216,\n",
      "         324,  216,  324,  216, 1296,  216,  216,  324,  324,  324, 1296,  324,\n",
      "         216,  324,  216,  324,  216,  216,  216,  324,  324,  216,  324,  324,\n",
      "         324,  324, 1296,  324,  324,  216,  216,  216,  324,  324,  324,  324,\n",
      "         216,  216,  324,  216,  216,  216,  216,  216,  216,  216, 1296,  216,\n",
      "         216,  216,  216,  324,  324,  216,  216,  216])\n",
      "train >  1251 val >  251\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import Grayscale\n",
    "# 데이터 경로\n",
    "data_root = f'D:/data/training/sources/cropped'\n",
    "\n",
    "# 데이터 변환: 이미지 데이:?\"터를 흑백데이터로 변환해 학습하기\n",
    "data_transforms = transforms.Compose([\n",
    "    Grayscale(num_output_channels=1),  # 흑백 변환 (1 채널)\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485], [0.229])  # 흑백 이미지의 경우 평균과 표준편차는 하나의 값만 사용\n",
    "])\n",
    "\n",
    "# ImageFolder로 전체 데이터셋 생성\n",
    "dataset = datasets.ImageFolder(root=data_root, transform=data_transforms)\n",
    "\n",
    "# 데이터셋 분할 (예: 80% 훈련, 20% 검증)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "\n",
    "\n",
    "# 클래스별 샘플 수 계산\n",
    "class_counts = torch.bincount(torch.tensor(train_dataset.dataset.targets))\n",
    "print('클래스별 샘플 수:', class_counts)\n",
    "\n",
    "# 클래스별 데이터 샘플 수를 기반으로 WeightedRandomSampler를 사용하여 샘플링\n",
    "# 클래스 가중치: 클래스별 역수로 계산 => 샘플 수가 적을수록 가중치가 높아짐\n",
    "class_weights = 1.0 / class_counts.double()\n",
    "# 클래스 가중치 적용\n",
    "sample_weights = class_weights[train_dataset.dataset.targets]\n",
    "# WeightedRandomSampler를 이용해 데이터 샘플링\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "\n",
    "# 데이터 로더 생성\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dataloaders_dict = {'train': train_dataloader, 'val': valid_dataloader}\n",
    "\n",
    "print('train > ', len(train_dataloader), 'val > ', len(valid_dataloader))\n",
    "# # 리스트를 텍스트 파일로 저장하기\n",
    "# with open(f'save/classes_batch{batch_size}.pkl', 'wb') as f:\n",
    "#     pickle.dump(dataset.classes, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T23:55:38.567735600Z",
     "start_time": "2023-10-10T23:55:24.435306200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train_classes = set()\n",
    "# for data in tqdm_notebook(train_dataset):\n",
    "#     _, label = data  # 데이터와 레이블을 분리\n",
    "#     train_classes.add(label)  # 레이블을 set에 추가하여 중복 클래스 제거\n",
    "#\n",
    "# num_train_classes = len(train_classes)\n",
    "# print(\"훈련 데이터셋 클래스 수:\", num_train_classes)\n",
    "#\n",
    "# valid_classes = set()\n",
    "# for data in tqdm_notebook(valid_dataset):\n",
    "#     _, label = data\n",
    "#     valid_classes.add(label)\n",
    "#\n",
    "# num_valid_classes = len(valid_classes)\n",
    "# print(\"검증 데이터셋 클래스 수:\", num_valid_classes)\n",
    "#\n",
    "# test_classes = set()\n",
    "# for data in tqdm_notebook(test_dataset):\n",
    "#     _, label = data\n",
    "#     test_classes.add(label)\n",
    "#\n",
    "# num_test_classes = len(test_classes)\n",
    "# print(\"테스트 데이터셋 클래스 수:\", num_test_classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mobilenet, input_size = initialize_model(model_name='mobilenet', num_classes=500, use_pretrained=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.NAdam(mobilenet.parameters(), lr=0.0004)\n",
    "\n",
    "mobilenet, val_acc_history, val_top5_acc_history = train_models(mobilenet, dataloaders_dict, criterion, optimizer, num_epochs=10, is_inception=False, quantize=False)\n",
    "\n",
    "save_path = f'save/mobilenet_epoch10_batch128_pretrained_noQuantize.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': mobilenet.state_dict(),  # 모델 가중치 저장\n",
    "    'optimizer_state_dict': optimizer.state_dict(),  # 옵티마이저 상태 저장 (선택적)\n",
    "    'epoch': 10,  # 현재 학습 에폭 저장 (선택적) # 다른 필요한 정보 저장 (선택적)\n",
    "}, save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def testing_models(models, dataloaders_dict, num_epochs, num_classes=1000, feature_extract=False, use_pretrained=True, quantize=False):\n",
    "    acc = {}\n",
    "\n",
    "    for model_name in models:\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        model, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained, quantize=quantize)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.NAdam(model.parameters(), lr=0.001)\n",
    "\n",
    "        print('device > ', device)\n",
    "        print(f'{model_name} / pretrained({use_pretrained}) / quantize({quantize})')\n",
    "\n",
    "        model, hist, top5_hist = train_models(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs, is_inception=False, quantize=quantize)\n",
    "\n",
    "        acc[model_name] = {\n",
    "            'top1': hist,\n",
    "            'top5': top5_hist\n",
    "        }\n",
    "\n",
    "    return accuracies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = 'mobilenet'\n",
    "num_epochs = 2\n",
    "quantize = False\n",
    "model, hist, top5_hist = train_models(model_name, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs, is_inception=False, quantize=quantize)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# models = ['mobilenet', 'mnasnet', 'efficientnet', 'shufflenet']\n",
    "accuracies_quantized = testing_models(models=['mobilenet'], dataloaders_dict=dataloaders_dict, num_epochs=5, num_classes=500, feature_extract=False, use_pretrained=True, quantize=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracies= testing_models(models=['mobilenet'], dataloaders_dict=dataloaders_dict, num_epochs=5, num_classes=500, feature_extract=False, use_pretrained=True, quantize=False)\n",
    "print(accuracies)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('save/accuracies.json', 'w') as f:\n",
    "    json.dump(accuracies, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_path = f'save/mobilenet_epoch10.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': mobilenet.state_dict(),  # 모델 가중치 저장\n",
    "    'optimizer_state_dict': optimizer.state_dict(),  # 옵티마이저 상태 저장 (선택적)\n",
    "    'epoch': 10,  # 현재 학습 에폭 저장 (선택적) # 다른 필요한 정보 저장 (선택적)\n",
    "}, save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracies['mnasnet']['top5']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "num_epochs = 5\n",
    "plt.title(\"Top1 Validation Accuracy\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),losses['mobilenet']['top1'],label=\"mobilenet\", color='purple')\n",
    "plt.plot(range(1,num_epochs+1),losses['mnasnet']['top1'],label=\"mnasnet\", color='red')\n",
    "plt.plot(range(1,num_epochs+1),losses['efficientnet']['top1'],label=\"efficientnet\", color='yellow')\n",
    "plt.plot(range(1,num_epochs+1),losses['shufflenet']['top1'],label=\"shufflenet\", color='green')\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "plt.title(\"Top5 Validation Accuracy\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),losses['mobilenet']['top5'],label=\"mobilenet\", color='purple')\n",
    "plt.plot(range(1,num_epochs+1),losses['mnasnet']['top5'],label=\"mnasnet\", color='red')\n",
    "plt.plot(range(1,num_epochs+1),losses['efficientnet']['top5'],label=\"efficientnet\", color='yellow')\n",
    "plt.plot(range(1,num_epochs+1),losses['shufflenet']['top5'],label=\"shufflenet\", color='green')\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "plt.title(\"Mobilenet Validation Accuracy: top1 VS top5\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),val_acc_history,label=\"top1 accuracy\", color='purple')\n",
    "plt.plot(range(1,num_epochs+1),val_top5_acc_history,label=\"top5 accuracy\", color='green')\n",
    "\n",
    "plt.ylim((0,1.))\n",
    "plt.yticks([0.8, 0.9, 1.0])\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 이미지 추론"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 모델 불러올 경로 설정\n",
    "# load_path = f'save/{model_name}_epoch{num_epochs}_quntize({quantize}.pth)'\n",
    "from PIL import Image\n",
    "\n",
    "# 이미지 추론 코드\n",
    "def infer(image_path, image_label):\n",
    "    since = time.time()\n",
    "    image = Image.open(image_path)\n",
    "    label = image_label\n",
    "    desired_size = (224, 224)\n",
    "    image = image.resize(desired_size)\n",
    "\n",
    "    # 모델 및 다른 정보 불러오기\n",
    "    load_path = 'save/mobilenet_epoch10_batch128_pretrained_noQuantize.pth'\n",
    "    checkpoint = torch.load(load_path)\n",
    "    model = CustomMobileNetV3Large(num_classes=500)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])  # 모델 가중치 불러오기\n",
    "    print(f'Model loaded from {load_path}')\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # 사진을 모델 입력에 맞게 resize\n",
    "    preprocess  = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    input_tensor = preprocess(image).unsqueeze(0)\n",
    "    print('input tensor 사이즈 > ', input_tensor.size())\n",
    "    print(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor.to(device))\n",
    "\n",
    "    _, predicted_index = torch.max(outputs, 1)\n",
    "    predicted_index = predicted_index.item()\n",
    "\n",
    "    # 클래스 이름\n",
    "    with open('save/classes_batch128.pkl', 'rb') as pickle_file:\n",
    "        classes = pickle.load(pickle_file)\n",
    "        predicted_class = classes[predicted_index]\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    # 모델이 예측한 클래스 인덱스 출력\n",
    "    print('='*20)\n",
    "    print('예측된 클래스 인덱스: ', predicted_index)\n",
    "    print('클래스 이름: ', predicted_class)\n",
    "    print('일치여부(클래스): ', predicted_class==label)\n",
    "    # print('일치여부(타겟): ', predicted_index==label)\n",
    "    print('추론 시간: ', end_time-since)\n",
    "    print('='*20)\n",
    "\n",
    "    return predicted_class, predicted_class==label\n",
    "\n",
    "# sample1: uncropped\n",
    "image1_path = 'save/K-039306(cropped).jpg'\n",
    "image1_label = 'K-039306'\n",
    "image1_predictiton, image1_correct = infer(image1_path, image1_label)\n",
    "\n",
    "# sample2: cropped\n",
    "image2_path = 'save/K-039306(uncropped).jpg'\n",
    "image2_label = 'K-039306'\n",
    "image2_predictiton, image2_correct = infer(image2_path, image2_label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델들의 GFLOPS & Parameters 비교"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_size = (batch_size, 3, 224, 224)  # (배치 크기, 채널 수, 높이, 너비)\n",
    "\n",
    "# 모델 불러와 적용하기\n",
    "\n",
    "# model_names = ['mobilenet', 'mobilenet(quantized)', 'efficientnet', 'shufflenet']\n",
    "model_names = ['mobilenet', 'efficientnet', 'shufflenet']\n",
    "gflops_list = []\n",
    "params_list = []\n",
    "# mobilenet\n",
    "mobilenet = CustomMobileNetV3Large(num_classes=500)\n",
    "checkpoint = torch.load('save/CustomMobileNetV3Large_epoch5_quntize(False).pth')\n",
    "mobilenet.load_state_dict(checkpoint['model_state_dict'])  # 모델 가중치 불러오기\n",
    "optimizer = torch.optim.NAdam(mobilenet.parameters(), lr=0.001)\n",
    "mobilenet.eval()\n",
    "# 모델의 FLOPs 계산\n",
    "macs, params = profile(mobilenet, inputs=(torch.randn(*input_size),))\n",
    "gflops_list.append(round(macs / 1e9, 3))\n",
    "params_list.append(int(params/1000000))\n",
    "\n",
    "# mobilenet(quantized)\n",
    "# mobilenet_quantized = QuantizedCustomMobileNetV3Large(num_classes=500)\n",
    "# checkpoint = torch.load('save/CustomMobileNetV3Large_epoch5_quntize(False).pth')\n",
    "# mobilenet.load_state_dict(checkpoint['model_state_dict'])  # 모델 가중치 불러오기\n",
    "# optimizer = torch.optim.NAdam(mobilenet_quantized.parameters(), lr=0.001)\n",
    "# mobilenet.eval()\n",
    "# macs, params = profile(mobilenet_quantized, inputs=(torch.randn(*input_size),))\n",
    "# gflops_list.append(round(macs / 1e9, 3))\n",
    "# params_list.append(int(params/1000000))\n",
    "\n",
    "# 모델 불러와 적용하기\n",
    "efficientnet = models.efficientnet_b0(num_classes=500)\n",
    "checkpoint = torch.load('save/EfficientNet_epoch5_quntize(False).pth')\n",
    "efficientnet.load_state_dict(checkpoint['model_state_dict'])  # 모델 가중치 불러오기\n",
    "optimizer = torch.optim.NAdam(efficientnet.parameters(), lr=0.001)\n",
    "efficientnet.eval()\n",
    "macs, params = profile(efficientnet, inputs=(torch.randn(*input_size),))\n",
    "gflops_list.append(round(macs / 1e9, 3))\n",
    "params_list.append(int(params/1000000))\n",
    "\n",
    "# shufflenet\n",
    "shufflenet = models.shufflenet_v2_x2_0(num_classes=500)\n",
    "checkpoint = torch.load('save/ShuffleNetV2_epoch5_quntize(False).pth')\n",
    "shufflenet.load_state_dict(checkpoint['model_state_dict'])  # 모델 가중치 불러오기\n",
    "optimizer = torch.optim.NAdam(shufflenet.parameters(), lr=0.001)\n",
    "shufflenet.eval()\n",
    "macs, params = profile(shufflenet, inputs=(torch.randn(*input_size),))\n",
    "gflops_list.append(round(macs / 1e9, 3))\n",
    "params_list.append(int(params/1000000))\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Comparison of GFLOPs in Different Models')\n",
    "plt.xlabel('GFLOPs')\n",
    "plt.legend(loc='best')\n",
    "plt.bar(model_names, gflops_list, alpha=0.7, width=0.4, label='GFLOPs', color='b')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Comparison of number of Parameters(M) in Different Models')\n",
    "plt.xlabel('Parameters(M)')\n",
    "plt.legend(loc='best')\n",
    "plt.bar(model_names, params_list, alpha=0.7, width=0.4, label='Parameters(M)', color='g')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 테스트"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_model():\n",
    "  model = CustomMobileNetV3Large(num_classes=500)\n",
    "  checkpoint = torch.load('save/CustomMobileNetV3Large_epoch5_quntize(False).pth')\n",
    "  model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "  return model\n",
    "\n",
    "def test(test_dataloader):\n",
    "    model = get_model().eval()\n",
    "    correct = 0\n",
    "    top5_correct = 0\n",
    "    total = 0\n",
    "    predict_list = []\n",
    "    # 그라디언트 계산 비활성화 (테스트 모드)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm_notebook(test_dataloader):\n",
    "            outputs = model(inputs)\n",
    "            _, top5 = torch.topk(outputs, k=5, dim=1)  # 상위 5개 예측을 가져옵니다.\n",
    "            total += labels.size(0)\n",
    "            # print(label, ' > ', predicted[:, 0] == labels)\n",
    "            top1 = top5[:, 0]\n",
    "            predict_list.append()\n",
    "            correct += (top5[:, 0] == labels).sum().item()  # 상위 1개 예측이 정답과 일치하는 경우\n",
    "            for i in range(5):\n",
    "                top5_correct += (top5[:, i] == labels).sum().item()  # 상위 5개 예측 중 하나가 정답과 일치하는 경우\n",
    "\n",
    "    accuracy = correct / total\n",
    "    top5_accuracy = top5_correct / total\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Top-5 Accuracy: {top5_accuracy * 100:.2f}%\")\n",
    "\n",
    "    return accuracy, top5_accuracy, predict_list\n",
    "\n",
    "accuracy, top5_accuracy, predict_list = test(test_dataloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## VIT 적용 및 학습"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "# 클래스 수\n",
    "num_classes = 500\n",
    "\n",
    "# 하이퍼파라미터\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 5\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []  # 이미지 파일 경로 리스트\n",
    "        self.labels = []  # 레이블 리스트\n",
    "\n",
    "        # 이미지 파일 경로와 레이블 로드\n",
    "        # 예: 이미지 파일 경로가 data_dir/class_name/image.jpg 형식일 때\n",
    "        for class_idx, class_name in enumerate(os.listdir(data_dir)):\n",
    "            class_path = os.path.join(data_dir, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                for image_name in os.listdir(class_path):\n",
    "                    image_path = os.path.join(class_path, image_name)\n",
    "                    self.image_paths.append(image_path)\n",
    "                    self.labels.append(class_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# 데이터 전처리 및 DataLoader 설정\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(data_dir=f'D:/data/training/sources/cropped', transform=data_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# ViT 모델 로드\n",
    "model_name = \"google/vit-base-patch16-224-in21k\"\n",
    "feature_extractor = ViTFeatureExtractor(model_name)\n",
    "model = ViTForImageClassification.from_pretrained(model_name)\n",
    "classifier = nn.Linear(model.config.hidden_size, num_classes)\n",
    "model.classifier = classifier\n",
    "\n",
    "# 옵티마이저 및 손실 함수 설정\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 학습 루프\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm_notebook(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_path = f'save/vit_eph{num_epochs}.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': mobilenet.state_dict(),  # 모델 가중치 저장\n",
    "    'optimizer_state_dict': optimizer.state_dict(),  # 옵티마이저 상태 저장 (선택적)\n",
    "    'epoch': num_epochs,  # 현재 학습 에폭 저장 (선택적) # 다른 필요한 정보 저장 (선택적)\n",
    "}, save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 추론\n",
    "model.eval()\n",
    "\n",
    "# 추론할 이미지 전처리\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = data_transform(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    return image.to(device)\n",
    "\n",
    "# 추론할 이미지 파일 경로\n",
    "input_image_path = 'save/K-039306(cropped).jpg'\n",
    "\n",
    "# 이미지 추론\n",
    "with torch.no_grad():\n",
    "    input_image = preprocess_image(input_image_path)\n",
    "    outputs = model(input_image)\n",
    "    _, predicted = torch.max(outputs.logits, 1)\n",
    "\n",
    "# 예측 결과 출력\n",
    "print(f\"Predicted class: {predicted.item()}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
