{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 필요한 모듈들 임포트"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine tuning\n",
    "사전 훈련된 모델을 기반으로 아키텍쳐를 새로운 목적에 맞게 변형하고 이미 학습된 모델의 가중치를 미세하게 조정해 학습시키는 방법\n",
    "    - 사전 훈련된 모델의 가중치를 초기값으로 사용하고 추가로 학습\n",
    "    - CNN 베이스의 사전학습 모델을 사용할 때에는 이전에 학습한 내용들을 모두 잊어버릴 위험이 있기 때문에 작은 learning rate를 사용하는것이 바람직함\n",
    "[방법1] 모델 전체를 새로 학습\n",
    "- 사전 학습 모델의 구조만 사용하면서, 자신의 데이터셋에 맞게 모델을 전부 새롭게 학습시키는 방법\n",
    "- 데이터의 크기가 크고 유사성이 작을 때 사용\n",
    "[방법2] Conv base는 일부분 고정(Freezing)하고 나머지 Conv Base 계층과 Classifier를 새롭게 학습\n",
    "- Conv base: 합성곱 층과 풀링 층이 여러 겹 쌓여있는 부분으로 특징을 추출하는 역할\n",
    "- Classifier: 주로 완전연결계층으로 구성되며 Conv base가 추출한 특징들을 잘 학습해 각각의 샘플들을 알맞은 class로 분류\n",
    "- 낮은 레벨의 계층은 일반적이고 독리적인 특징(신형성)을 추출하고, 높은 레벨의 계층은 구체적이고 명확한 특징(형상)을 추출\n",
    "- 크기가  크고 유사성도 높은 데이터셋일 때\n",
    "[방법3] Conv Base는 고정하고 Classifier만 새로 학습\n",
    "- 컴퓨팅 연산 능력이 부족하거나, 데이터셋이 너무 작을 때, 혹은 적용하려는 task와 사전학습에 쓰인 데이터가 매우 비슷할 때 사용\n",
    "\n",
    "[크기가 작고 유사성도 작은 데이터]\n",
    "- 방법2를 쓰되 조금 더 깊은 계층까지 새로 학습시키\n",
    "- Data Augmentation 하기\n",
    "\n",
    "[Feature Extraction]\n",
    "사전 훈련된 모델의 하위 층을 동결하고, 상위 층을 새로운 작업을 위해 수정하지 않고 사용하는 것 -> 데이터분류기(마지막 완전연결층) 부분만 새로 만드는 것\n",
    "    - 사전 훈련된 모델(고정): 중요한 특성 추출(학습 X)\n",
    "    - 데이터분류기: 추출된 특성을 입력받아 최종적으로 이미지에 대한 클래스를 분류(학습O)\n",
    "    - 가능한 모델: Xception, Inception V3, ResNet50, VGG16, VGG19, MobileNet\n",
    "\n",
    "[ 분류기 수정하는 방법 ]\n",
    "Fine tunning을 하기 전 input값으로 받는 이미지의 크기는 무조건 확인해야함\n",
    "    - 대부분의 모델은 (224, 224)이지만 inception_v3의 경우 (299, 299)\n",
    "1. print(model)로 마지막 층의 in_features 확인\n",
    "2. nn.Linear(in_features, num_classes)로 클래스 수 변경\n",
    "    - 예시1: Resnet\n",
    "        - (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
    "            - => model.fc = nn.Linear(512, num_classes)\n",
    "    - 예시2: Alexnet\n",
    "        - (classifier): Sequential(... (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "            - => model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "    - 예시3(특이구조): Squeezenet\n",
    "        - - output은 classifier의 첫번째 레이어인 1X1 convolution layer로부터 나옴\n",
    "        - (classifier): Sequential((0): Dropout(p=0.5)  (1): Conv2d(512, 1000, kernel_size=13, stride=1, padding=0)  (2): ReLU(inplace)  (3): AvgPool2d(kernel_size=13, stride=1, padding=0))\n",
    "            -  => model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "    - 예시4(특이구조): Inception v3\n",
    "        - Rethinking을 하기 때문에 학습과정에서 output이 두개의 레이어로부터 나옴\n",
    "        - 두번째 output(auxiliary output): AuxLogits 부분을 포함하는 네트워크에 포함됨\n",
    "        - 주된 output은 네트워크의 마지막 레이어에서 출력됨\n",
    "            -  test 시에는 이 output만 고려함\n",
    "        - (AuxLogits): InceptionAux(... (fc): Linear(in_feature=768, out_features=1000, bias=True) ... (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
    "            -  finetune 하기 위해서는 두 레이어를 reshape 해줘야함\n",
    "            -  => model.AuxLogits.fc = nn.Linear(768, num_classes)\n",
    "            -  model.fc = nn.Linear(2048, nuum_classes)\n",
    "\n",
    "[ 사용가능한 함수들 ]\n",
    "- get_model(name, **config): 모델 이름과 환경설정을 인수로 받아 해당 모델의 인스턴스를 반환\n",
    "    - get_model(\"quantized_mobilenet_v3_large\", weights=\"DEFAULT\")\n",
    "- get_model_weight(name): 해당 모델의 열거형 가중치 클래스 반환\n",
    "    - 예1: get_model_weights(\"quantized_mobilenet_v3_large\")\n",
    "    - 예2: get_model_weights(torchvision.models.quantization.mobilenet_v3_large)\n",
    "    - 예1 = 예2\n",
    "- get_weight(name): 열거형 가중치 변수의 이름으로 값을 가져옴\n",
    "    - 예: get_weight(\"MobileNet_V3_Large_QuantizedWeights.DEFAULT\")\n",
    "- list_models(\\[module]): 해당 이름으로 등록된 모델 목록을 반환\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 사용가능한 모델 확인\n",
    "# for name in dir(torchvision.models):\n",
    "#     print(name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 구성"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "\"\"\"\n",
    "        MobileNet V3 main class\n",
    "\n",
    "        Args:\n",
    "            inverted_residual_setting (List[InvertedResidualConfig]): Network structure\n",
    "            last_channel (int): The number of channels on the penultimate layer\n",
    "            num_classes (int): Number of classes\n",
    "            block (Optional[Callable[..., nn.Module]]): Module specifying inverted residual building block for mobilenet\n",
    "            norm_layer (Optional[Callable[..., nn.Module]]): Module specifying the normalization layer to use\n",
    "            dropout (float): The droupout probability\n",
    "        \"\"\"\n",
    "# MobileNetV3 Large 모델 구현\n",
    "class CustomMobileNetV3Large(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(CustomMobileNetV3Large, self).__init__()\n",
    "        self.features = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V2, progress=True).features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(960, num_classes, 1, 1, 0),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 양자화를 고려한 학습: MobileNetV3 Large\n",
    "class QuantizedCustomMobileNetV3Large(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(QuantizedCustomMobileNetV3Large, self).__init__()\n",
    "        '''\n",
    "            [ 양자화 ]\n",
    "            - 모델의 가중치와 활성화 값을 낮은 비트 수로 표현하여 모델을 경량화하고 속도를 향상시키는 기술\n",
    "            - Stub: 모델 내에서 양자화 연산을 수행하기 전과 후에 데이터의 변환을 지원하는 역할\n",
    "            - QuantStub(): 모델의 입력 데이터를 양자화된 형태로 변환하고, 양자화된 형태에서 연산을 수행\n",
    "            - DeQuantStugb(): 양자화된 출력을 다시 원래 형태의 실수 값으로 변환\n",
    "        '''\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        self.features = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.DEFAULT, progress=True).features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(960, num_classes, 1, 1, 0),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)  # 양자화\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        x = self.dequant(x)  # 되돌리기\n",
    "        return x\n",
    "\n",
    "\n",
    "# class CustomMnasNet1_3(nn.Module):\n",
    "#     def __init__(self, num_classes=1000):\n",
    "#         super(CustomMnasNet1_3, self).__init__()\n",
    "#         # MNASNet의 Convolutional 레이어를 추출하여 features로 설정\n",
    "#         self.features = models.mnasnet1_3(weights=models.MNASNet1_3_Weights.DEFAULT, progress=True).layers\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Dropout(p=0.2, inplace=True),\n",
    "#             nn.Linear(in_features=1280, out_features=num_classes, bias=True)\n",
    "#         )\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n",
    "\n",
    "class CustomMnasNet1_3(models.MNASNet):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(CustomMnasNet1_3, self).__init__(num_classes=num_classes, pretrained=True)\n",
    "\n",
    "        # 기본 MNASNet 모델의 classifier 부분을 새로운 classifier로 교체\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2, inplace=True),\n",
    "            nn.Linear(in_features=1280, out_features=num_classes, bias=True)\n",
    "        )\n",
    "\n",
    "\n",
    "class QuantizedCustomMnasNet1_3(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(QuantizedCustomMnasNet1_3, self).__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        # MNASNet의 Convolutional 레이어를 추출하여 features로 설정\n",
    "        self.features = nn.Sequential(*list(models.mnasnet1_3(weights=models.MNASNet1_3_Weights.DEFAULT, progress=True).children())[:-1])  # 마지막 Fully Connected 레이어 제외\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2, inplace=True),\n",
    "            nn.Linear(in_features=1280, out_features=num_classes, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        x = self.dequant(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = CustomMnasNet1_3(num_classes=500)\n",
    "# model = models.mnasnet1_3(weights=models.MNASNet1_3_Weights.DEFAULT, progress=True)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 추론 - 임의의 이미지"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img = cv2.imread('apple.jpg')\n",
    "img = transform_test(img).unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(img.to(device))\n",
    "\n",
    "_, predicted_class = torch.max(outputs, 1)\n",
    "predicted_class = predicted_class.item()\n",
    "predicted_class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 작업중"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "model_list = ['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet', 'inception', 'mobilenet']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 모델학습 헬퍼 함수\n",
    "def train_models(model, dataloaders, criterion, optimizer, num_epochs=10, is_inception=False, quantize=False):\n",
    "    torch.cuda.empty_cache()\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    val_top5_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    patience = 3\n",
    "    no_improvement_count = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1} / {num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # 각 에폭은 학습/검증 phase를 가짐\n",
    "        for phase in ['train', 'val']:\n",
    "            print(f'>>>>> phase: {phase}<<<<<')\n",
    "            if phase == 'train':\n",
    "                model.train()  # 트레이닝 모드 설정\n",
    "            else:\n",
    "                if quantize == True:\n",
    "                    # 모델을 양자화 + 추론모드\n",
    "                    model = torch.quantization.convert(model.eval(), inplace=False)\n",
    "                else:\n",
    "                    model.eval()  # 추론 모드 설정\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_top5_corrects = 0\n",
    "\n",
    "            # 데이터 학습하기\n",
    "            for inputs, labels in tqdm_notebook(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # 파라미터 기울기 초기화\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # 학습 모드인 경우에만 history 추적\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # 모델의 ouptut과 loss를 구함\n",
    "                    # inception의 경우 학습시 auxiliary output이 있는 특수 케이스임.\n",
    "                    #   학습시: final output과 auxiliary output을 더하는 과정이 필요함\n",
    "                    #   테스트시: final output만 고려\n",
    "                    # Auxilary output을 같이 고려해야하는 학습단계\n",
    "                    if is_inception and phase == 'train':\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4 * loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # top-5 정확도 계산\n",
    "                    _,top5_preds = torch.topk(outputs, 5)\n",
    "                    top5_corrects = torch.sum(top5_preds == labels.view(-1, 1))\n",
    "\n",
    "                    # 학습(backward + optimize)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # loss 구하기\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                running_top5_corrects += top5_corrects\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            epoch_top5_acc = running_top5_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # 모델 깊은복사\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                no_improvement_count = 0  # 개선이 있었으므로 카운트 초기화\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                val_top5_acc_history.append(epoch_top5_acc)\n",
    "                no_improvement_count += 1  # 개선이 없었으므로 카운트\n",
    "\n",
    "            # Early Stopping 확인\n",
    "            if no_improvement_count >= patience:\n",
    "                print(f\"No improvement in validation accuracy for {patience} epochs. Early stopping...\")\n",
    "                break  # 학습 종료\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.4f}'.format(best_acc))\n",
    "    print('Best top5 val Acc: {:.4f}'.format(epoch_top5_acc))\n",
    "\n",
    "    # 베스트 모델 가중치를 로드\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, val_top5_acc_history"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 모델 파라미터의 requires_grad 속성\n",
    "- 기본적으로 사전  훈련된 모델을 로드할 때 모든 매개변수의 requires_grad = True로 설정되어 있음\n",
    "    - True: 처음부터 훈련하거나 fine tuning할 때는 True\n",
    "    - False(Freeze): 기존 layer의 weight를 고정"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True, quantize=False):\n",
    "    # 모델마다 다르게 지정될 변수들 초기화\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == 'resnet':\n",
    "        if quantize:\n",
    "            '''Quantized Resnet50'''\n",
    "            weights = models.quantization.ResNet50_QuantizedWeights.DEFAULT\n",
    "            model_ft = models.quantization.resnet50(weights=weights, quantize=True)\n",
    "        else:\n",
    "            '''Resnet50'''\n",
    "            model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'mobilenet':\n",
    "        if quantize:\n",
    "            '''Quantized Mobilenet v3 large'''\n",
    "            model_ft = QuantizedCustomMobileNetV3Large(num_classes=500).to(device)\n",
    "\n",
    "            # 양자화 설정 - gbgemm 백엔드 사용\n",
    "            backend = 'fbgemm'\n",
    "            # 양자화 스키마 설정 (예: symmetric)\n",
    "            quantization_params = torch.quantization.get_default_qconfig(backend)\n",
    "            quantization_params = torch.quantization.QConfig(activation=quantization_params.activation, weight=quantization_params.weight)\n",
    "\n",
    "            # 양자화 준비\n",
    "            model.qconfig = quantization_params\n",
    "            model_ft= torch.quantization.prepare_qat(model_ft, inplace=False)\n",
    "\n",
    "        else:\n",
    "            model_ft = CustomMobileNetV3Large(num_classes=500).to(device)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'mnasnet':\n",
    "        if quantize:\n",
    "            '''Quantized Mnasnet 1_3'''\n",
    "            model_ft = QuantizedCustomMnasNet1_3(num_classes=500).to(device)\n",
    "\n",
    "            # 양자화 설정 - gbgemm 백엔드 사용\n",
    "            backend = 'fbgemm'\n",
    "            model_ft.qconfig = torch.quantization.get_default_qat_qconfig(backend)\n",
    "\n",
    "            # 양자화 준비\n",
    "            model_ft= torch.quantization.prepare_qat(model_ft, inplace=False)\n",
    "\n",
    "        else:\n",
    "            model_ft = models.mnasnet1_3(weights=models.MNASNet1_3_Weights.IMAGENET1K_V1)\n",
    "            num_ftrs = model_ft.classifier[1].in_features\n",
    "            model_ft.classifier[1] = nn.Linear(in_features=1280, out_features=num_classes, bias=True)\n",
    "            # model_ft = CustomMnasNet1_3(num_classes=500).to(device)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'efficientnet':\n",
    "        if quantize:\n",
    "            pass\n",
    "        else:\n",
    "            model_ft = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "            num_ftrs = model_ft.classifier[1].in_features\n",
    "            model_ft.classifier[1] = nn.Linear(num_ftrs, num_classes, bias=True)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'shufflenet':\n",
    "        if quantize:\n",
    "            pass\n",
    "        else:\n",
    "            model_ft = models.shufflenet_v2_x2_0(weights=models.ShuffleNet_V2_X2_0_Weights.IMAGENET1K_V1)\n",
    "            num_ftrs = model_ft.fc.in_features\n",
    "            model_ft.fc = nn.Linear(num_ftrs, num_classes, bias=True)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'alexnet':\n",
    "        '''AlexNet'''\n",
    "        model_ft = models.alexnet(pretrianed=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_featrues\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'vgg':\n",
    "        '''VGG11_bn'''\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'squeezenet':\n",
    "        '''Squeezenet 1.0'''\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'densenet':\n",
    "        '''Densenet 121'''\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'inception':\n",
    "        '''Inception V3'''\n",
    "        if quantize:\n",
    "            weights = models.quantization.Inception_V3_QuantizedWeights.DEFAULT\n",
    "            model_ft = models.quantization.inception_v3(weights=weights, quantize=True)\n",
    "        else:\n",
    "            model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 299  # 다른 모델과 다르게 299 사이즈를 사용\n",
    "    else:\n",
    "        print('모델의 이름을 잘못 입력하여 종료합니다...')\n",
    "        exit()\n",
    "\n",
    "    return model_ft.to(device), input_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 초기화"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 데이터 경로\n",
    "data_root = f'D:/data/training/sources/cropped'\n",
    "\n",
    "# 데이터 변환\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ImageFolder로 전체 데이터셋 생성\n",
    "dataset = datasets.ImageFolder(root=data_root, transform=data_transforms)\n",
    "\n",
    "# 데이터셋 분할 (예: 80% 훈련, 20% 유효성 검사)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
    "valid_dataset, test_dataset = random_split(valid_dataset, [0.9, 0.1])\n",
    "\n",
    "# 데이터 로더 생성\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# dataloaders_dict = {'train': train_dataloader, 'val': valid_dataloader, 'test': test_dataloader}\n",
    "dataloaders_dict = {'train': test_dataloader, 'val': test_dataloader}  # 1epoch 동작여부 빠르게 확인용\n",
    "\n",
    "print('train > ', len(train_dataloader), '\\nval > ', len(valid_dataloader), '\\ntest > ', len(test_dataloader))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# mobilenet, mnasnet, efficientnet, shufflenet\n",
    "model_name = 'efficientnet'\n",
    "num_classes = 500\n",
    "feature_extract = False\n",
    "use_pretrained = True\n",
    "quantize = False\n",
    "\n",
    "model_efficientnet, input_size_efficientnet = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained, quantize=quantize)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.NAdam(model_efficientnet.parameters(), lr=0.001)\n",
    "\n",
    "print('device > ', device)\n",
    "print(f'{model_name} / pretrained({use_pretrained}) / quantize({quantize})')\n",
    "num_epochs = 5\n",
    "model_efficientnet, hist_efficientnet, top5_hist_efficientne = train_models(model_efficientnet, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs, is_inception=False, quantize=quantize)\n",
    "\n",
    "# 모델 및 다른 정보 저장\n",
    "save_path = f'save/{model_name}_epoch{num_epochs}_quntize({quantize}).pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model_efficientnet.state_dict(),  # 모델 가중치 저장\n",
    "    'optimizer_state_dict': optimizer.state_dict(),  # 옵티마이저 상태 저장 (선택적)\n",
    "    'epoch': num_epochs,  # 현재 학습 에폭 저장 (선택적)\n",
    "    # 다른 필요한 정보 저장 (선택적)\n",
    "}, save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# mobilenet, mnasnet, efficientnet, shufflenet\n",
    "model_name = 'shufflenet'\n",
    "num_classes = 500\n",
    "feature_extract = False\n",
    "use_pretrained = True\n",
    "quantize = False\n",
    "\n",
    "model_shufflenet, input_size_shufflenet = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained, quantize=quantize)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.NAdam(model_shufflenet.parameters(), lr=0.001)\n",
    "\n",
    "print('device > ', device)\n",
    "print(f'{model_name} / pretrained({use_pretrained}) / quantize({quantize})')\n",
    "num_epochs = 5\n",
    "model_shufflenet, hist_shufflenet, top5_hist_shufflene = train_models(model_shufflenet, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs, is_inception=False, quantize=quantize)\n",
    "\n",
    "# 모델 및 다른 정보 저장\n",
    "save_path = f'save/{model_name}_epoch{num_epochs}_quntize({quantize}).pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model_shufflenet.state_dict(),  # 모델 가중치 저장\n",
    "    'optimizer_state_dict': optimizer.state_dict(),  # 옵티마이저 상태 저장 (선택적)\n",
    "    'epoch': num_epochs,  # 현재 학습 에폭 저장 (선택적)\n",
    "    # 다른 필요한 정보 저장 (선택적)\n",
    "}, save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# mobilenet, mnasnet, efficientnet, shufflenet\n",
    "model_name = 'mobilenet'\n",
    "num_classes = 500\n",
    "feature_extract = False\n",
    "use_pretrained = True\n",
    "quantize = False\n",
    "\n",
    "model_mobilenet, input_size_mobilenet = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained, quantize=quantize)\n",
    "model_mobilenet = model_mobilenet.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.NAdam(model_mobilenet.parameters(), lr=0.001)\n",
    "\n",
    "print('device > ', device)\n",
    "print(f'{model_name} / pretrained({use_pretrained}) / quantize({quantize})')\n",
    "num_epochs = 5\n",
    "model_mobilenet, hist_mobilene, top5_hist_mobilene = train_models(model_mobilenet, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs, is_inception=False, quantize=quantize)\n",
    "\n",
    "# 모델 및 다른 정보 저장\n",
    "save_path = f'save/{model_name}_epoch{num_epochs}_quntize({quantize}).pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model_mobilenet.state_dict(),  # 모델 가중치 저장\n",
    "    'optimizer_state_dict': optimizer.state_dict(),  # 옵티마이저 상태 저장 (선택적)\n",
    "    'epoch': num_epochs,  # 현재 학습 에폭 저장 (선택적)\n",
    "    # 다른 필요한 정보 저장 (선택적)\n",
    "}, save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# mobilenet, mnasnet, efficientnet, shufflenet\n",
    "model_name = 'mnasnet'\n",
    "num_classes = 500\n",
    "feature_extract = False\n",
    "use_pretrained = True\n",
    "quantize = False\n",
    "\n",
    "model_mnasnet, input_size_mnasnet = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained, quantize=quantize)\n",
    "model_mnasnet = model_mnasnet.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.NAdam(model_mnasnet.parameters(), lr=0.001)\n",
    "\n",
    "print('device > ', device)\n",
    "print(f'{model_name} / pretrained({use_pretrained}) / quantize({quantize})')\n",
    "num_epochs = 5\n",
    "model_mnasnet, hist_mnasnet, top5_hist_mnasne = train_models(model_mnasnet, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs, is_inception=False, quantize=quantize)\n",
    "\n",
    "# 모델 및 다른 정보 저장\n",
    "save_path = f'save/{model_name}_epoch{num_epochs}_quntize({quantize}).pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model_mnasnet.state_dict(),  # 모델 가중치 저장\n",
    "    'optimizer_state_dict': optimizer.state_dict(),  # 옵티마이저 상태 저장 (선택적)\n",
    "    'epoch': num_epochs,  # 현재 학습 에폭 저장 (선택적)\n",
    "    # 다른 필요한 정보 저장 (선택적)\n",
    "}, save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(model_mnasnet)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 테스트 데이터셋\n",
    "# 모델 불러올 경로 설정\n",
    "load_path = f'save/{model_name}_epoch{num_epochs}_quntize({quantize}.pth)'\n",
    "\n",
    "# 모델 및 다른 정보 불러오기\n",
    "checkpoint = torch.load(load_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])  # 모델 가중치 불러오기\n",
    "\n",
    "# 옵티마이저 상태 불러오기 (필요한 경우)\n",
    "if 'optimizer_state_dict' in checkpoint:\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# 학습 에폭 불러오기 (선택적)\n",
    "if 'epoch' in checkpoint:\n",
    "    epoch = checkpoint['epoch']\n",
    "\n",
    "# 모델을 평가 모드로 설정 (모델 불러온 후 필요한 경우)\n",
    "model.eval()\n",
    "\n",
    "print(f'Model loaded from {load_path}')\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm_notebook(test_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_pretrained"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_scratch, input_size_scratch = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained, quantize=quantize)\n",
    "model_scratch = model_scratch.to(device)\n",
    "\n",
    "model_scratch, hist_scratch = train_models(model_scratch, dataloaders_dict, criterion, optimizer, num_epochs=1, is_inception=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from thop import profile\n",
    "\n",
    "# 입력 크기 정의 (예: 3 채널, 224x224 크기의 이미지)\n",
    "input_size = (128, 3, 224, 224)  # (배치 크기, 채널 수, 높이, 너비)\n",
    "\n",
    "# 모델의 FLOPs 계산\n",
    "macs, params = profile(model_scratch, inputs=(torch.randn(*input_size).to(device),))\n",
    "print(\"FLOPs: {:.4f} G FLOPs\".format(macs / 1e9))  # 결과를 기가 FLOPs로 표시합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "ohist = []\n",
    "shist = []\n",
    "num_epochs=1\n",
    "ohist = [h.cpu().numpy() for h in hist_pretrained]\n",
    "shist = [h.cpu().numpy() for h in hist_scratch]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_pretrained2, hist_pretrained2 = train_models(model_pretrained, dataloaders_dict, criterion, optimizer, num_epochs=1, is_inception=False)\n",
    "model_scratch2, hist_scratch2 = train_models(model_scratch, dataloaders_dict, criterion, optimizer, num_epochs=1, is_inception=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 모델 인스턴스 생성하고 구조 확인하기\n",
    "# # 1. 일반 레즈넷, 마지막 fc레이어만 변경\n",
    "# model_name = 'resnet'\n",
    "# num_classes = 500\n",
    "# feature_extract = False\n",
    "# use_pretrained = True\n",
    "# quantize = False\n",
    "#\n",
    "# model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True, quantize=False)\n",
    "# print(model_name)\n",
    "# print(model_ft)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 2. 양자화된 레즈넷, 마지막 fc레이어만 변경 - QuantizedLinear 나와야하는데 일반 Linear만나옴\n",
    "# model_name = 'resnet'\n",
    "# num_classes = 100\n",
    "# feature_extract = False\n",
    "# use_pretrained = True\n",
    "# quantize = True\n",
    "#\n",
    "# model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True, quantize=True)\n",
    "# print('quantized ' + model_name)\n",
    "# print(model_ft)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 헬퍼함수 없이 만든 양자화된 레즈넷\n",
    "# weights = models.quantization.ResNet50_QuantizedWeights.DEFAULT\n",
    "# model_ft = models.quantization.resnet50(weights=weights, quantize=True)\n",
    "# print(model_ft)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# weights = models.quantization.MobileNet_V3_Large_QuantizedWeights.DEFAULT\n",
    "# model_ft = models.quantization.mobilenet_v3_large(weigts=weights, quantize=True)\n",
    "# print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
