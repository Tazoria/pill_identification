{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 필요한 모듈들 임포트"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine tuning\n",
    "사전 훈련된 모델을 기반으로 아키텍쳐를 새로운 목적에 맞게 변형하고 이미 학습된 모델의 가중치를 미세하게 조정해 학습시키는 방법\n",
    "    - 사전 훈련된 모델의 가중치를 초기값으로 사용하고 추가로 학습\n",
    "    - CNN 베이스의 사전학습 모델을 사용할 때에는 이전에 학습한 내용들을 모두 잊어버릴 위험이 있기 때문에 작은 learning rate를 사용하는것이 바람직함\n",
    "[방법1] 모델 전체를 새로 학습\n",
    "- 사전 학습 모델의 구조만 사용하면서, 자신의 데이터셋에 맞게 모델을 전부 새롭게 학습시키는 방법\n",
    "- 데이터의 크기가 크고 유사성이 작을 때 사용\n",
    "[방법2] Conv base는 일부분 고정(Freezing)하고 나머지 Conv Base 계층과 Classifier를 새롭게 학습\n",
    "- Conv base: 합성곱 층과 풀링 층이 여러 겹 쌓여있는 부분으로 특징을 추출하는 역할\n",
    "- Classifier: 주로 완전연결계층으로 구성되며 Conv base가 추출한 특징들을 잘 학습해 각각의 샘플들을 알맞은 class로 분류\n",
    "- 낮은 레벨의 계층은 일반적이고 독리적인 특징(신형성)을 추출하고, 높은 레벨의 계층은 구체적이고 명확한 특징(형상)을 추출\n",
    "- 크기가  크고 유사성도 높은 데이터셋일 때\n",
    "[방법3] Conv Base는 고정하고 Classifier만 새로 학습\n",
    "- 컴퓨팅 연산 능력이 부족하거나, 데이터셋이 너무 작을 때, 혹은 적용하려는 task와 사전학습에 쓰인 데이터가 매우 비슷할 때 사용\n",
    "\n",
    "[크기가 작고 유사성도 작은 데이터]\n",
    "- 방법2를 쓰되 조금 더 깊은 계층까지 새로 학습시키\n",
    "- Data Augmentation 하기\n",
    "\n",
    "[Feature Extraction]\n",
    "사전 훈련된 모델의 하위 층을 동결하고, 상위 층을 새로운 작업을 위해 수정하지 않고 사용하는 것 -> 데이터분류기(마지막 완전연결층) 부분만 새로 만드는 것\n",
    "    - 사전 훈련된 모델(고정): 중요한 특성 추출(학습 X)\n",
    "    - 데이터분류기: 추출된 특성을 입력받아 최종적으로 이미지에 대한 클래스를 분류(학습O)\n",
    "    - 가능한 모델: Xception, Inception V3, ResNet50, VGG16, VGG19, MobileNet\n",
    "\n",
    "[ 분류기 수정하는 방법 ]\n",
    "Fine tunning을 하기 전 input값으로 받는 이미지의 크기는 무조건 확인해야함\n",
    "    - 대부분의 모델은 (224, 224)이지만 inception_v3의 경우 (299, 299)\n",
    "1. print(model)로 마지막 층의 in_features 확인\n",
    "2. nn.Linear(in_features, num_classes)로 클래스 수 변경\n",
    "    - 예시1: Resnet\n",
    "        - (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
    "            - => model.fc = nn.Linear(512, num_classes)\n",
    "    - 예시2: Alexnet\n",
    "        - (classifier): Sequential(... (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "            - => model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "    - 예시3(특이구조): Squeezenet\n",
    "        - - output은 classifier의 첫번째 레이어인 1X1 convolution layer로부터 나옴\n",
    "        - (classifier): Sequential((0): Dropout(p=0.5)  (1): Conv2d(512, 1000, kernel_size=13, stride=1, padding=0)  (2): ReLU(inplace)  (3): AvgPool2d(kernel_size=13, stride=1, padding=0))\n",
    "            -  => model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "    - 예시4(특이구조): Inception v3\n",
    "        - Rethinking을 하기 때문에 학습과정에서 output이 두개의 레이어로부터 나옴\n",
    "        - 두번째 output(auxiliary output): AuxLogits 부분을 포함하는 네트워크에 포함됨\n",
    "        - 주된 output은 네트워크의 마지막 레이어에서 출력됨\n",
    "            -  test 시에는 이 output만 고려함\n",
    "        - (AuxLogits): InceptionAux(... (fc): Linear(in_feature=768, out_features=1000, bias=True) ... (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
    "            -  finetune 하기 위해서는 두 레이어를 reshape 해줘야함\n",
    "            -  => model.AuxLogits.fc = nn.Linear(768, num_classes)\n",
    "            -  model.fc = nn.Linear(2048, nuum_classes)\n",
    "\n",
    "[ 사용가능한 함수들 ]\n",
    "- get_model(name, **config): 모델 이름과 환경설정을 인수로 받아 해당 모델의 인스턴스를 반환\n",
    "    - get_model(\"quantized_mobilenet_v3_large\", weights=\"DEFAULT\")\n",
    "- get_model_weight(name): 해당 모델의 열거형 가중치 클래스 반환\n",
    "    - 예1: get_model_weights(\"quantized_mobilenet_v3_large\")\n",
    "    - 예2: get_model_weights(torchvision.models.quantization.mobilenet_v3_large)\n",
    "    - 예1 = 예2\n",
    "- get_weight(name): 열거형 가중치 변수의 이름으로 값을 가져옴\n",
    "    - 예: get_weight(\"MobileNet_V3_Large_QuantizedWeights.DEFAULT\")\n",
    "- list_models(\\[module]): 해당 이름으로 등록된 모델 목록을 반환\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from thop import profile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "from custom_models import CustomMobileNetV3Large, QuantizedCustomMobileNetV3Large, CustomMnasNet1_3, QuantizedCustomMnasNet1_3\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "model_list = ['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet', 'inception', 'mobilenet']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 모델학습 헬퍼 함수\n",
    "def train_models(model, dataloaders, criterion, optimizer, num_epochs=10, is_inception=False, quantize=False):\n",
    "    torch.cuda.empty_cache()\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    val_top5_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    patience = 3\n",
    "    no_improvement_count = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1} / {num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # 각 에폭은 학습/검증 phase를 가짐\n",
    "        for phase in ['train', 'val']:\n",
    "            print(f'>>>>> phase: {phase}<<<<<')\n",
    "            if phase == 'train':\n",
    "                model.train()  # 트레이닝 모드 설정\n",
    "            else:\n",
    "                if quantize == True:\n",
    "                    # 모델을 양자화 + 추론모드\n",
    "                    model = torch.quantization.convert(model.eval(), inplace=False)\n",
    "                else:\n",
    "                    model.eval()  # 추론 모드 설정\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_top5_corrects = 0\n",
    "\n",
    "            # 데이터 학습하기\n",
    "            for inputs, labels in tqdm_notebook(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # 파라미터 기울기 초기화\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # 학습 모드인 경우에만 history 추적\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # 모델의 ouptut과 loss를 구함\n",
    "                    # inception의 경우 학습시 auxiliary output이 있는 특수 케이스임.\n",
    "                    #   학습시: final output과 auxiliary output을 더하는 과정이 필요함\n",
    "                    #   테스트시: final output만 고려\n",
    "                    # Auxilary output을 같이 고려해야하는 학습단계\n",
    "                    if is_inception and phase == 'train':\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4 * loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # top-5 정확도 계산\n",
    "                    _,top5_preds = torch.topk(outputs, 5)\n",
    "                    top5_corrects = torch.sum(top5_preds == labels.view(-1, 1))\n",
    "\n",
    "                    # 학습(backward + optimize)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        if (epoch + 1) % 5 == 0:\n",
    "                            # 모델 및 다른 정보 저장\n",
    "                            save_path = f'save/{type(model).__name__}_epoch{epoch+1}_quntize({quantize}).pth'\n",
    "                            torch.save({\n",
    "                                'model_state_dict': model.state_dict(),  # 모델 가중치 저장\n",
    "                                'optimizer_state_dict': optimizer.state_dict(),  # 옵티마이저 상태 저장 (선택적)\n",
    "                                'epoch': epoch+1,  # 현재 학습 에폭 저장 (선택적)\n",
    "                                # 다른 필요한 정보 저장 (선택적)\n",
    "                            }, save_path)\n",
    "\n",
    "                # loss 구하기\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                running_top5_corrects += top5_corrects\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            epoch_top5_acc = running_top5_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # 모델 깊은복사\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                no_improvement_count = 0  # 개선이 있었으므로 카운트 초기화\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc.item())\n",
    "                val_top5_acc_history.append(epoch_top5_acc.item())\n",
    "                no_improvement_count += 1  # 개선이 없었으므로 카운트\n",
    "\n",
    "            # Early Stopping 확인\n",
    "            # if no_improvement_count >= patience:\n",
    "            #     print(f\"No improvement in validation accuracy for {patience} epochs. Early stopping...\")\n",
    "            #     break  # 학습 종료\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.4f}'.format(best_acc))\n",
    "    print('Best top5 val Acc: {:.4f}'.format(epoch_top5_acc))\n",
    "\n",
    "    # 베스트 모델 가중치를 로드\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, val_top5_acc_history\n",
    "\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 모델 파라미터의 requires_grad 속성\n",
    "- 기본적으로 사전  훈련된 모델을 로드할 때 모든 매개변수의 requires_grad = True로 설정되어 있음\n",
    "    - True: 처음부터 훈련하거나 fine tuning할 때는 True\n",
    "    - False(Freeze): 기존 layer의 weight를 고정"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=True, quantize=False):\n",
    "    # 모델마다 다르게 지정될 변수들 초기화\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == 'resnet':\n",
    "        if quantize:\n",
    "            '''Quantized Resnet50'''\n",
    "            weights = models.quantization.ResNet50_QuantizedWeights.DEFAULT\n",
    "            model_ft = models.quantization.resnet50(weights=weights, quantize=True)\n",
    "        else:\n",
    "            '''Resnet50'''\n",
    "            model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'mobilenet':\n",
    "        if quantize:\n",
    "            '''Quantized Mobilenet v3 large'''\n",
    "            model_ft = QuantizedCustomMobileNetV3Large(num_classes=500).to(device)\n",
    "\n",
    "            # 양자화 설정 - gbgemm 백엔드 사용\n",
    "            backend = 'fbgemm'\n",
    "            # 양자화 스키마 설정 (예: symmetric)\n",
    "            quantization_params = torch.quantization.get_default_qconfig(backend)\n",
    "            quantization_params = torch.quantization.QConfig(activation=quantization_params.activation, weight=quantization_params.weight)\n",
    "\n",
    "            # 양자화 준비\n",
    "            model.qconfig = quantization_params\n",
    "            model_ft= torch.quantization.prepare_qat(model_ft, inplace=False)\n",
    "\n",
    "        else:\n",
    "            model_ft = CustomMobileNetV3Large(num_classes=500).to(device)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'mnasnet':\n",
    "        if quantize:\n",
    "            '''Quantized Mnasnet 1_3'''\n",
    "            model_ft = QuantizedCustomMnasNet1_3(num_classes=500).to(device)\n",
    "\n",
    "            # 양자화 설정 - gbgemm 백엔드 사용\n",
    "            backend = 'fbgemm'\n",
    "            model_ft.qconfig = torch.quantization.get_default_qat_qconfig(backend)\n",
    "\n",
    "            # 양자화 준비\n",
    "            model_ft= torch.quantization.prepare_qat(model_ft, inplace=False)\n",
    "\n",
    "        else:\n",
    "            model_ft = models.mnasnet1_3(weights=models.MNASNet1_3_Weights.IMAGENET1K_V1)\n",
    "            num_ftrs = model_ft.classifier[1].in_features\n",
    "            model_ft.classifier[1] = nn.Linear(in_features=1280, out_features=num_classes, bias=True)\n",
    "            # model_ft = CustomMnasNet1_3(num_classes=500).to(device)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'efficientnet':\n",
    "        if quantize:\n",
    "            pass\n",
    "        else:\n",
    "            model_ft = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "            num_ftrs = model_ft.classifier[1].in_features\n",
    "            model_ft.classifier[1] = nn.Linear(num_ftrs, num_classes, bias=True)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'shufflenet':\n",
    "        if quantize:\n",
    "            pass\n",
    "        else:\n",
    "            model_ft = models.shufflenet_v2_x2_0(weights=models.ShuffleNet_V2_X2_0_Weights.IMAGENET1K_V1)\n",
    "            num_ftrs = model_ft.fc.in_features\n",
    "            model_ft.fc = nn.Linear(num_ftrs, num_classes, bias=True)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'alexnet':\n",
    "        '''AlexNet'''\n",
    "        model_ft = models.alexnet(pretrianed=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_featrues\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'vgg':\n",
    "        '''VGG11_bn'''\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'squeezenet':\n",
    "        '''Squeezenet 1.0'''\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'densenet':\n",
    "        '''Densenet 121'''\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'inception':\n",
    "        '''Inception V3'''\n",
    "        if quantize:\n",
    "            weights = models.quantization.Inception_V3_QuantizedWeights.DEFAULT\n",
    "            model_ft = models.quantization.inception_v3(weights=weights, quantize=True)\n",
    "        else:\n",
    "            model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 299  # 다른 모델과 다르게 299 사이즈를 사용\n",
    "    else:\n",
    "        print('모델의 이름을 잘못 입력하여 종료합니다...')\n",
    "        exit()\n",
    "\n",
    "    return model_ft.to(device), input_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 초기화"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 데이터 경로\n",
    "data_root = f'D:/data/training/sources/cropped'\n",
    "\n",
    "# 데이터 변환\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ImageFolder로 전체 데이터셋 생성\n",
    "dataset = datasets.ImageFolder(root=data_root, transform=data_transforms)\n",
    "\n",
    "# 데이터셋 분할 (예: 80% 훈련, 20% 유효성 검사)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
    "# valid_dataset, test_dataset = random_split(valid_dataset, [0.8, 0.2])\n",
    "\n",
    "# 데이터 로더 생성\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dataloaders_dict = {'train': train_dataloader, 'val': valid_dataloader}\n",
    "# dataloaders_dict = {'train': valid_dataloader, 'val': test_dataloader}  # 성능 빠르게 확인용\n",
    "# dataloaders_dict = {'train': test_dataloader, 'val': test_dataloader}  # 코드 돌아가는지 확인용\n",
    "\n",
    "print('train > ', len(train_dataloader), '\\nval > ', len(valid_dataloader))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mobilenet, input_size = initialize_model(model_name='mobilenet', num_classes=500, use_pretrained=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.NAdam(mobilenet.parameters(), lr=0.001)\n",
    "\n",
    "mobilenet, val_acc_history, val_top5_acc_history = train_models(mobilenet, dataloaders_dict, criterion, optimizer, num_epochs=10, is_inception=False, quantize=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def testing_models(dataloaders_dict, num_epochs, num_classes=1000, feature_extract=False, use_pretrained=True, quantize=False):\n",
    "    acc = {}\n",
    "\n",
    "    for model_name in ['mobilenet', 'mnasnet', 'efficientnet', 'shufflenet']:\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        model, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained, quantize=quantize)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.NAdam(model.parameters(), lr=0.001)\n",
    "\n",
    "        print('device > ', device)\n",
    "        print(f'{model_name} / pretrained({use_pretrained}) / quantize({quantize})')\n",
    "\n",
    "        model, hist, top5_hist = train_models(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs, is_inception=False, quantize=quantize)\n",
    "\n",
    "        acc[model_name] = {\n",
    "            'top1': hist,\n",
    "            'top5': top5_hist\n",
    "        }\n",
    "\n",
    "    return losses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "losses = testing_models(dataloaders_dict, num_epochs=5, num_classes=500, feature_extract=False, use_pretrained=True, quantize=False)\n",
    "\n",
    "print(losses)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('save/losses.json', 'w') as f:\n",
    "    json.dump(losses, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_path = f'save/mobilenet_epoch10.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': mobilenet.state_dict(),  # 모델 가중치 저장\n",
    "    'optimizer_state_dict': optimizer.state_dict(),  # 옵티마이저 상태 저장 (선택적)\n",
    "    'epoch': 10,  # 현재 학습 에폭 저장 (선택적) # 다른 필요한 정보 저장 (선택적)\n",
    "}, save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "losses['mnasnet']['top5']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "num_epochs = 5\n",
    "plt.title(\"Top1 Validation Accuracy\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),losses['mobilenet']['top1'],label=\"mobilenet\", color='purple')\n",
    "plt.plot(range(1,num_epochs+1),losses['mnasnet']['top1'],label=\"mnasnet\", color='red')\n",
    "plt.plot(range(1,num_epochs+1),losses['efficientnet']['top1'],label=\"efficientnet\", color='yellow')\n",
    "plt.plot(range(1,num_epochs+1),losses['shufflenet']['top1'],label=\"shufflenet\", color='green')\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "plt.title(\"Top5 Validation Accuracy\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),losses['mobilenet']['top5'],label=\"mobilenet\", color='purple')\n",
    "plt.plot(range(1,num_epochs+1),losses['mnasnet']['top5'],label=\"mnasnet\", color='red')\n",
    "plt.plot(range(1,num_epochs+1),losses['efficientnet']['top5'],label=\"efficientnet\", color='yellow')\n",
    "plt.plot(range(1,num_epochs+1),losses['shufflenet']['top5'],label=\"shufflenet\", color='green')\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "plt.title(\"Mobilenet Validation Accuracy: top1 VS top5\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),val_acc_history,label=\"top1 accuracy\", color='purple')\n",
    "plt.plot(range(1,num_epochs+1),val_top5_acc_history,label=\"top5 accuracy\", color='green')\n",
    "\n",
    "plt.ylim((0,1.))\n",
    "plt.yticks([0.8, 0.9, 1.0])\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_size = (batch_size, 3, 224, 224)  # (배치 크기, 채널 수, 높이, 너비)\n",
    "\n",
    "# 모델 불러와 적용하기\n",
    "mobilenet = CustomMobileNetV3Large(num_classes=500)\n",
    "checkpoint = torch.load('save/CustomMobileNetV3Large_epoch5_quntize(False).pth')\n",
    "mobilenet.load_state_dict(checkpoint['model_state_dict'])  # 모델 가중치 불러오기\n",
    "optimizer = torch.optim.NAdam(mobilenet.parameters(), lr=0.001)\n",
    "\n",
    "# 모델을 평가 모드로 설정\n",
    "mobilenet.eval()\n",
    "\n",
    "# 모델의 FLOPs 계산\n",
    "macs, params = profile(mobilenet, inputs=(torch.randn(*input_size),))\n",
    "FLOPs_mobilenet = macs / 1e9\n",
    "print(\"FLOPs: {:.4f} G FLOPs\".format(macs / 1e9))  # 결과를 기가 FLOPs로 표시합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_size = (batch_size, 3, 224, 224)  # (배치 크기, 채널 수, 높이, 너비)\n",
    "\n",
    "# 모델 불러와 적용하기\n",
    "efficientnet = models.efficientnet_b0(num_classes=500)\n",
    "checkpoint = torch.load('save/EfficientNet_epoch5_quntize(False).pth')\n",
    "efficientnet.load_state_dict(checkpoint['model_state_dict'])  # 모델 가중치 불러오기\n",
    "optimizer = torch.optim.NAdam(efficientnet.parameters(), lr=0.001)\n",
    "\n",
    "# 모델을 평가 모드로 설정\n",
    "efficientnet.eval()\n",
    "\n",
    "# 모델의 FLOPs 계산\n",
    "macs, params = profile(efficientnet, inputs=(torch.randn(*input_size),))\n",
    "FLOPs_efficientnet = macs / 1e9\n",
    "print(\"FLOPs: {:.4f} G FLOPs\".format(macs / 1e9))  # 결과를 기가 FLOPs로 표시합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_size = (batch_size, 3, 224, 224)  # (배치 크기, 채널 수, 높이, 너비)\n",
    "\n",
    "# 모델 불러와 적용하기\n",
    "shufflenet = models.shufflenet_v2_x2_0(num_classes=500)\n",
    "checkpoint = torch.load('save/ShuffleNetV2_epoch5_quntize(False).pth')\n",
    "shufflenet.load_state_dict(checkpoint['model_state_dict'])  # 모델 가중치 불러오기\n",
    "optimizer = torch.optim.NAdam(shufflenet.parameters(), lr=0.001)\n",
    "\n",
    "# 모델을 평가 모드로 설정\n",
    "efficientnet.eval()\n",
    "\n",
    "# 모델의 FLOPs 계산\n",
    "macs, params = profile(shufflenet, inputs=(torch.randn(*input_size),))\n",
    "FLOPs_shufflenet = macs / 1e9\n",
    "print(\"FLOPs: {:.4f} G FLOPs\".format(macs / 1e9))  # 결과를 기가 FLOPs로 표시합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('mobilenet FLPOs > ', FLOPs_mobilenet)\n",
    "print('efficientnet FLPOs > ', FLOPs_efficientnet)\n",
    "print('shufflene FLPOs > ', FLOPs_shufflenet)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 모델 및 다른 정보 저장\n",
    "save_path = f'save/{model_name}_epoch{num_epochs}_quntize({quantize}).pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model_efficientnet.state_dict(),  # 모델 가중치 저장\n",
    "    'optimizer_state_dict': optimizer.state_dict(),  # 옵티마이저 상태 저장 (선택적)\n",
    "    'epoch': num_epochs,  # 현재 학습 에폭 저장 (선택적)\n",
    "    # 다른 필요한 정보 저장 (선택적)\n",
    "}, save_path)\n",
    "\n",
    "\n",
    "# 모델 불러올 경로 설정\n",
    "load_path = f'save/{model_name}_epoch{num_epochs}_quntize({quantize}.pth)'\n",
    "\n",
    "# 모델 및 다른 정보 불러오기\n",
    "checkpoint = torch.load(load_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])  # 모델 가중치 불러오기\n",
    "\n",
    "# 옵티마이저 상태 불러오기 (필요한 경우)\n",
    "if 'optimizer_state_dict' in checkpoint:\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# 학습 에폭 불러오기 (선택적)\n",
    "if 'epoch' in checkpoint:\n",
    "    epoch = checkpoint['epoch']\n",
    "\n",
    "# 모델을 평가 모드로 설정 (모델 불러온 후 필요한 경우)\n",
    "model.eval()\n",
    "\n",
    "print(f'Model loaded from {load_path}')\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm_notebook(test_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 추론코드\n",
    "\n",
    "img = cv2.imread('apple.jpg')\n",
    "img = transform_test(img).unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(img.to(device))\n",
    "\n",
    "_, predicted_class = torch.max(outputs, 1)\n",
    "predicted_class = predicted_class.item()\n",
    "predicted_class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 모델 인스턴스 생성하고 구조 확인하기\n",
    "# # 1. 일반 레즈넷, 마지막 fc레이어만 변경\n",
    "# model_name = 'resnet'\n",
    "# num_classes = 500\n",
    "# feature_extract = False\n",
    "# use_pretrained = True\n",
    "# quantize = False\n",
    "#\n",
    "# model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True, quantize=False)\n",
    "# print(model_name)\n",
    "# print(model_ft)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 2. 양자화된 레즈넷, 마지막 fc레이어만 변경 - QuantizedLinear 나와야하는데 일반 Linear만나옴\n",
    "# model_name = 'resnet'\n",
    "# num_classes = 100\n",
    "# feature_extract = False\n",
    "# use_pretrained = True\n",
    "# quantize = True\n",
    "#\n",
    "# model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True, quantize=True)\n",
    "# print('quantized ' + model_name)\n",
    "# print(model_ft)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 헬퍼함수 없이 만든 양자화된 레즈넷\n",
    "# weights = models.quantization.ResNet50_QuantizedWeights.DEFAULT\n",
    "# model_ft = models.quantization.resnet50(weights=weights, quantize=True)\n",
    "# print(model_ft)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# weights = models.quantization.MobileNet_V3_Large_QuantizedWeights.DEFAULT\n",
    "# model_ft = models.quantization.mobilenet_v3_large(weigts=weights, quantize=True)\n",
    "# print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
